{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-t6lyJo95oOr"
      },
      "source": [
        "## *PROJEKT BBC NEWS CLASIFICATION*\n",
        "Julia Żółtowska"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset: BBC articles fulltext and category. Zbiór zawiera 2225 artykułów ze strony BBC news\n",
        "website w formie dokumnetów tekstowych, podzielonych na 5 grup: business, tech, sport,\n",
        "entertaiment, politics. Atrybuty tesktowe: Kategoria, TekstArtykułuTytuł"
      ],
      "metadata": {
        "id": "6TZ06wFpM6Ee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Preprocessing text\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHE9NKwv1Eox",
        "outputId": "99eed462-66ca-4e99-841b-b2f6c274329b"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Wczytanie danych\n",
        "articles = pd.read_csv('/content/drive/MyDrive/Projekt_WUM/dane/bbc-text.csv')\n",
        "articles.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "aBEx3Zic1LC3",
        "outputId": "2e396cff-8868-4912-eff6-a7cb27d28ddd"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        category                                               text\n",
              "0           tech  tv future in the hands of viewers with home th...\n",
              "1       business  worldcom boss  left books alone  former worldc...\n",
              "2          sport  tigers wary of farrell  gamble  leicester say ...\n",
              "3          sport  yeading face newcastle in fa cup premiership s...\n",
              "4  entertainment  ocean s twelve raids box office ocean s twelve..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d4b91230-b67b-406b-b24c-41b72bf3974d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tech</td>\n",
              "      <td>tv future in the hands of viewers with home th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>business</td>\n",
              "      <td>worldcom boss  left books alone  former worldc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sport</td>\n",
              "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sport</td>\n",
              "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d4b91230-b67b-406b-b24c-41b72bf3974d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d4b91230-b67b-406b-b24c-41b72bf3974d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d4b91230-b67b-406b-b24c-41b72bf3974d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Eksploracyjna Analiza Danych (EDA)"
      ],
      "metadata": {
        "id": "spaMUqYK1fBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Wyświetlenie szczegółowych informacji o kolumnach\n",
        "articles.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLP_GvM61kiU",
        "outputId": "d0c48997-3fa8-4aa8-986e-c96018516889"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2225 entries, 0 to 2224\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   category  2225 non-null   object\n",
            " 1   text      2225 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 34.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Wyświetlenie kategorii artykułów w datasetcie articles\n",
        "articles['category'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZiCyWjU1nq0",
        "outputId": "b190b921-57bb-4d87-c6b6-211cf597bb60"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['tech', 'business', 'sport', 'entertainment', 'politics'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Grupuję dane na podstawie kategorii\n",
        "articles.groupby('category').count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "AEKd411F1xmu",
        "outputId": "005b4cfd-6929-4ac3-b425-704ec1213b05"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               text\n",
              "category           \n",
              "business        510\n",
              "entertainment   386\n",
              "politics        417\n",
              "sport           511\n",
              "tech            401"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1b987288-07b1-4e8a-9380-941b93b68c1b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>category</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>business</th>\n",
              "      <td>510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>entertainment</th>\n",
              "      <td>386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>politics</th>\n",
              "      <td>417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sport</th>\n",
              "      <td>511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tech</th>\n",
              "      <td>401</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b987288-07b1-4e8a-9380-941b93b68c1b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1b987288-07b1-4e8a-9380-941b93b68c1b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1b987288-07b1-4e8a-9380-941b93b68c1b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Przegladam dataset na podstawie długości tekstu atrykułu i wyświetlam 10 pierwszych wierszy\n",
        "articles['length'] = articles['text'].apply(len)\n",
        "articles.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "ciHi1Te82nBV",
        "outputId": "ccd2b368-7a21-42a3-a930-f63c44484c66"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        category                                               text  length\n",
              "0           tech  tv future in the hands of viewers with home th...    4333\n",
              "1       business  worldcom boss  left books alone  former worldc...    1842\n",
              "2          sport  tigers wary of farrell  gamble  leicester say ...    1342\n",
              "3          sport  yeading face newcastle in fa cup premiership s...    2176\n",
              "4  entertainment  ocean s twelve raids box office ocean s twelve...    1579\n",
              "5       politics  howard hits back at mongrel jibe michael howar...    3533\n",
              "6       politics  blair prepares to name poll date tony blair is...    1486\n",
              "7          sport  henman hopes ended in dubai third seed tim hen...    1051\n",
              "8          sport  wilkinson fit to face edinburgh england captai...     983\n",
              "9  entertainment  last star wars  not for children  the sixth an...    1248"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-945fa572-3035-4f5a-b22a-c14f193b1aa9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tech</td>\n",
              "      <td>tv future in the hands of viewers with home th...</td>\n",
              "      <td>4333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>business</td>\n",
              "      <td>worldcom boss  left books alone  former worldc...</td>\n",
              "      <td>1842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sport</td>\n",
              "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
              "      <td>1342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sport</td>\n",
              "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
              "      <td>2176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
              "      <td>1579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>politics</td>\n",
              "      <td>howard hits back at mongrel jibe michael howar...</td>\n",
              "      <td>3533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>politics</td>\n",
              "      <td>blair prepares to name poll date tony blair is...</td>\n",
              "      <td>1486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>sport</td>\n",
              "      <td>henman hopes ended in dubai third seed tim hen...</td>\n",
              "      <td>1051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>sport</td>\n",
              "      <td>wilkinson fit to face edinburgh england captai...</td>\n",
              "      <td>983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>last star wars  not for children  the sixth an...</td>\n",
              "      <td>1248</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-945fa572-3035-4f5a-b22a-c14f193b1aa9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-945fa572-3035-4f5a-b22a-c14f193b1aa9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-945fa572-3035-4f5a-b22a-c14f193b1aa9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#histogram przedstawiający rozkład wartości w kolumnie 'length'\n",
        "articles['length'].plot(bins=100,kind='hist')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "Nw8mXtUV28Nl",
        "outputId": "602efcae-5e6a-4d2d-e3f7-003d384bcad2"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: ylabel='Frequency'>"
            ]
          },
          "metadata": {},
          "execution_count": 110
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Wyświetlam  długość najdłuższego artykułu w datasetcie\n",
        "articles['length'].max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VassTW3d3NyJ",
        "outputId": "551d186b-d035-4b16-a8d0-3026c8975652"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25483"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#wyświetlam wartość kolumny \"category\" dla wierszy, w których długość artykułu jest nawiększa\n",
        "print(articles[articles['length'] == articles['length'].max()]['category'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FH3PNXhX3kuk",
        "outputId": "eb7a978e-d4df-43b6-cec6-71b9ba6e7106"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "408    politics\n",
            "Name: category, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Generuję histogramy, które pokazują rozkład wartości dotyczący długości artykułów w każdej kategorii\n",
        "articles.hist(column='length', by='category', bins=50, figsize=(12,8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 800
        },
        "id": "jv_e_kmp5fpH",
        "outputId": "6f79f211-23ab-40ea-dd4a-5011e829fa2d"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[<Axes: title={'center': 'business'}>,\n",
              "        <Axes: title={'center': 'entertainment'}>],\n",
              "       [<Axes: title={'center': 'politics'}>,\n",
              "        <Axes: title={'center': 'sport'}>],\n",
              "       [<Axes: title={'center': 'tech'}>, <Axes: >]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 113
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Przetwarzanie danych"
      ],
      "metadata": {
        "id": "9XiBYahe55Mf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Przygotowanie funkcji, która będzie wykorzystywana do przygotowania tekstu artykołów do klasyfikacji"
      ],
      "metadata": {
        "id": "vgyVGdM669_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def text_processing(text):\n",
        "\n",
        "    #TOKENIZACJA\n",
        "    # Wykonałam tokenizację tekstu artykułów, używając biblioteki NLTK, czyli Natural Language Toolkit\n",
        "    #Wykorzystałam funkcję word_tokenize, która dokonuje tokenizacji tekstu artykułów na poziomie słów.\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    #jako wynik otrzymałam liste tokenów, czyli słów\n",
        "\n",
        "    #USUWANIE STOP WORDS\n",
        "    # Następnie utworzyłam zbiór słów tzw. stop words dla języka angielskiego, które\n",
        "    #dostracza biblioteka NLTK, w związku z tym, że artykuły po angielsku\n",
        "    #to używam słów stop words z języka angielskiego.\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "\n",
        "    #Przeszłam po liście tokenów i sprawdzałam czy ten token nie znajduję się\n",
        "    #w zbiorze stop words, jeśli token nie jest tym, ze zbioru stop words\n",
        "    #to zostaje zachowany no i dodany do nowej listy tokens\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "    # USUWAM CYFRY, ZNAKI INTERPUNKCYJNE I SPECJALNE\n",
        "    regex = '[a-z]+' #używam  wzorca tak zwanego wyrażenia regularnego używanego do\n",
        "    #dopasowywania ciągów znaków, które składając się tylko z małych liter, czyli że token\n",
        "    #musi zawierać jedną albo więcej małych liter\n",
        "\n",
        "    #Przechodzę przez każdy token w liście tokens i sprawdzam, czy pasuje on do\n",
        "    #wzorca wyrażenia regex. Poprzez re.match(regex, word) sprawdzałam\n",
        "    #czy token pasuje do wzorca, jeśli pasuje to zostaje dodany do tokens\n",
        "    tokens = [word for word in tokens if re.match(regex, word)]\n",
        "    #Rezultat to, że zachowane są tylko te tokeny, które składają się tylko z małych liter.\n",
        "\n",
        "    # Lematyzacja: konwertowanie słów do ich podstawowej formy\n",
        "    lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
        "    #Stworzyłam obiekt lematyzatora z biblioteki NLTK\n",
        "    tokens = [lem.lemmatize(word, pos='v') for word in tokens]\n",
        "    #przechodzę przez każdy token i go lemantyzuję za pomocą metody lemmatize obiektu lem. Parametr pod='v', czyli\n",
        "    #słowo podczas lemnatyzacji traktowane jako ver,b czyli czasownik\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "sTCR_Tk5mcUB"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Przekształcenie etykiet z postaci tekstowej na numeryczną\n",
        " #użyłam Label Encodera, bo on analizuje unikalne wartości w kolumnie\n",
        "#,,category\"  no i tworzy mapowanie między tymi wartościami a liczbami całkowitymi np. artykuł z kategorii Sport może mieć po zastosowaniu kodowania etykietę 1\n",
        "label_encoder = LabelEncoder()\n",
        "articles['category_enc'] = label_encoder.fit_transform(articles['category'])\n",
        "#w wyniku otrzymałam nową kolumnę, która ma zakodowane wartości kategorii artykółów"
      ],
      "metadata": {
        "id": "CWpK1F367LVT"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sprawdzam jak wyglądają zakodowane klasy z kolumny category\n",
        "articles['category_enc']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KS37rqSfeBOJ",
        "outputId": "6c4b1944-6c64-4ac9-df96-58d24e456df2"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       4\n",
              "1       0\n",
              "2       3\n",
              "3       3\n",
              "4       1\n",
              "       ..\n",
              "2220    0\n",
              "2221    2\n",
              "2222    1\n",
              "2223    2\n",
              "2224    3\n",
              "Name: category_enc, Length: 2225, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Podział danych"
      ],
      "metadata": {
        "id": "BbVUEmDIjqRk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Dzielę dane na treningowe i testowe (stosunek 80:20)\n",
        "x_train, x_test, y_train, y_test = train_test_split(articles['text'], articles['category_enc'], test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "O4eHL-Fp7WfA"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dzielę dane treningowe na treningowe i walidacyjne (stosunek 80:20)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "EMxmcWSJCuNM"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bag of words - Tworzenie reprezentacji bag of words"
      ],
      "metadata": {
        "id": "uCoD7nFvjwuz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Najpierw wykorzystałam obiekt CountVectorizer, który przekszatłaca dane wejściowe na reprezentację numeryczną,\n",
        "#w którym każdy artykuł jest kodowany jako wektor, który zawiera konkretną liczbę wystąpień słów w tym artykule.\n",
        "#Dodatkowo do tego obiektu CountVectorizer przekazywana jest funkcja, którą wcześniej zdefiniowałam czyszcząca tekst atrykułów.\n",
        "bow_transformer = CountVectorizer(analyzer= text_processing).fit(x_train)\n",
        "\n",
        "#Następnie wykonałam przekształecenie bag of words na danych treningowych,walidacyjnych i testowych.\n",
        "x_train_bow = bow_transformer.transform(x_train)\n",
        "x_val_bow = bow_transformer.transform(x_val)\n",
        "x_test_bow = bow_transformer.transform(x_test)"
      ],
      "metadata": {
        "id": "uj-jA4rW7bRX"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF (Term Frequency-Inverse Document Frequency) - Konwersja reprezentacji bag of words na reprezentację TF-IDF"
      ],
      "metadata": {
        "id": "JwQ9w-ARma9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Tworzę obiekt TfidfTransformer z biblioteki scikit-learn, służący do obliczania wag TF-IDF dla\n",
        "#przekształconych reprezentacji Bag of Words a poprzez fit dostosowuje model do danych treningowych\n",
        "#i obliczam statystki, które są potrzebne do obliczenia wag TF-IDF.\n",
        "tfidf_transformer = TfidfTransformer().fit(x_train_bow)\n",
        "\n",
        "\n",
        "#Następnie wykouje przekształcenie reprezentacji Bag of Words danych treningowych, walidacyjnych i testowych na reprezentację TD-IDF\n",
        "#, w której wartości wektorów zostają przeskalowane na podstawie wag TF-IDF, wykorzystując stworzony obiekt tfidf_transformer\n",
        "\n",
        "x_train_tfidf = tfidf_transformer.transform(x_train_bow)\n",
        "x_val_tfidf = tfidf_transformer.transform(x_val_bow)\n",
        "x_test_tfidf = tfidf_transformer.transform(x_test_bow)\n"
      ],
      "metadata": {
        "id": "vyMyWCUk7eP-"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Konwersja rzadkich macierzy na gęste tablice numpy\n",
        "\n",
        " Przez to, że wcześniej zrobiłam przekształcenie TF-IDF na reprezentacjach Bag of Words dla danych treningowych, walidacyjnych i testowych w wyniku otrzymałam rzadkie macierze, które to przechowują dane w postaci skompresowanej. (przeczytałałam, że robi się tak, żeby efektywniej zarządzać pamięcią)\n",
        "\n",
        "Celem tej konwersji było to, żeby x_train_ready,  x_val_ready i x_test_ready przechowywały przekształcone reprezentacje TF-IDF jako gęste tablice numpy, co umożliwiło mi wykorzystanie ich w uczeniu modelu."
      ],
      "metadata": {
        "id": "2lYz5cU4sh4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_ready = x_train_tfidf.toarray()\n",
        "x_val_ready = x_val_tfidf.toarray()\n",
        "x_test_ready = x_test_tfidf.toarray()\n"
      ],
      "metadata": {
        "id": "-AaZgy1e7kPX"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Konwersja danych  do formatu one-hot encoded ( wykorzystuję one-hot encoding)"
      ],
      "metadata": {
        "id": "tBqYPM_pwEid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(label_encoder.classes_) #obliczyłam liczbę klas poprzez zliczenie tych unikalnych w obiekcie label_encoder.classes i wartość z zostaje\n",
        "#przypisane do num_classes\n",
        "\n",
        "#wykonałam przekształcenie etykiet treningowych, walidacyjnych i testowych na postać one-hot encoding\n",
        "#Użyłam funkcji \"to_categorical\", która przekształaca etykiety klas na postać binarnego kodu 1 of n, w którym każda klasa jest reprezetowana przez\n",
        "# wektor zer oraz jedynek o długości num_classes\n",
        "y_train_ready = to_categorical(y_train, num_classes)\n",
        "y_val_ready= to_categorical(y_val, num_classes)\n",
        "y_test_ready = to_categorical(y_test, num_classes)\n",
        "\n"
      ],
      "metadata": {
        "id": "DpDT7Srm7hQJ"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wytrenowanie modelu referencyjnego - BASELINE\n",
        "Definiuję, kompiluję oraz trenuję model jednokierunkowej, wielowarstwowej sieci neuronowej o pierwszej warstwie gęstej (Dense), zawierającą 16 neuronów i z funkcją aktywacji RELU. Drugą warstwą gęstą, która też ma 16 neuronów o funkcji aktywacji RELU. Trzecią warstwą gęstą (Dense) o rozmiarze num_classes, czyli liczbie klas (5) oraz funkcją aktywacji softmax."
      ],
      "metadata": {
        "id": "9A92qlaUYRP7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train_ready, y_train_ready,\n",
        "                    epochs=30, batch_size=200,\n",
        "                    validation_data=(x_val_ready, y_val_ready))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w40GuSl9JHUs",
        "outputId": "db244dce-e07c-477e-e1e2-beb211f7d709"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 1.5970 - accuracy: 0.2451 - val_loss: 1.5683 - val_accuracy: 0.3511\n",
            "Epoch 2/30\n",
            "8/8 [==============================] - 0s 48ms/step - loss: 1.5419 - accuracy: 0.4080 - val_loss: 1.5131 - val_accuracy: 0.4129\n",
            "Epoch 3/30\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 1.4739 - accuracy: 0.4565 - val_loss: 1.4514 - val_accuracy: 0.4213\n",
            "Epoch 4/30\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 1.4005 - accuracy: 0.5014 - val_loss: 1.3842 - val_accuracy: 0.4635\n",
            "Epoch 5/30\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 1.3173 - accuracy: 0.5569 - val_loss: 1.3153 - val_accuracy: 0.4860\n",
            "Epoch 6/30\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 1.2337 - accuracy: 0.5962 - val_loss: 1.2444 - val_accuracy: 0.5197\n",
            "Epoch 7/30\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 1.1481 - accuracy: 0.6187 - val_loss: 1.1728 - val_accuracy: 0.5365\n",
            "Epoch 8/30\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 1.0613 - accuracy: 0.6552 - val_loss: 1.1001 - val_accuracy: 0.5927\n",
            "Epoch 9/30\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.9742 - accuracy: 0.7577 - val_loss: 1.0283 - val_accuracy: 0.6433\n",
            "Epoch 10/30\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.8863 - accuracy: 0.7992 - val_loss: 0.9545 - val_accuracy: 0.6882\n",
            "Epoch 11/30\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.7995 - accuracy: 0.8188 - val_loss: 0.8829 - val_accuracy: 0.7079\n",
            "Epoch 12/30\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7139 - accuracy: 0.8258 - val_loss: 0.8097 - val_accuracy: 0.7331\n",
            "Epoch 13/30\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6287 - accuracy: 0.8750 - val_loss: 0.7397 - val_accuracy: 0.7781\n",
            "Epoch 14/30\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.5490 - accuracy: 0.9754 - val_loss: 0.6715 - val_accuracy: 0.8287\n",
            "Epoch 15/30\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4735 - accuracy: 0.9958 - val_loss: 0.6072 - val_accuracy: 0.8567\n",
            "Epoch 16/30\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4041 - accuracy: 0.9979 - val_loss: 0.5466 - val_accuracy: 0.8876\n",
            "Epoch 17/30\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.3421 - accuracy: 0.9986 - val_loss: 0.4918 - val_accuracy: 0.9017\n",
            "Epoch 18/30\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.2870 - accuracy: 0.9986 - val_loss: 0.4427 - val_accuracy: 0.9185\n",
            "Epoch 19/30\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.2398 - accuracy: 0.9986 - val_loss: 0.3997 - val_accuracy: 0.9298\n",
            "Epoch 20/30\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.2007 - accuracy: 0.9993 - val_loss: 0.3631 - val_accuracy: 0.9354\n",
            "Epoch 21/30\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.1683 - accuracy: 0.9993 - val_loss: 0.3316 - val_accuracy: 0.9382\n",
            "Epoch 22/30\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.1419 - accuracy: 0.9993 - val_loss: 0.3051 - val_accuracy: 0.9494\n",
            "Epoch 23/30\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.1202 - accuracy: 0.9993 - val_loss: 0.2821 - val_accuracy: 0.9522\n",
            "Epoch 24/30\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.1024 - accuracy: 0.9993 - val_loss: 0.2621 - val_accuracy: 0.9579\n",
            "Epoch 25/30\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0878 - accuracy: 1.0000 - val_loss: 0.2451 - val_accuracy: 0.9607\n",
            "Epoch 26/30\n",
            "8/8 [==============================] - 0s 47ms/step - loss: 0.0757 - accuracy: 1.0000 - val_loss: 0.2311 - val_accuracy: 0.9663\n",
            "Epoch 27/30\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.0659 - accuracy: 1.0000 - val_loss: 0.2192 - val_accuracy: 0.9691\n",
            "Epoch 28/30\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 0.0579 - accuracy: 1.0000 - val_loss: 0.2091 - val_accuracy: 0.9691\n",
            "Epoch 29/30\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 0.0512 - accuracy: 1.0000 - val_loss: 0.1999 - val_accuracy: 0.9691\n",
            "Epoch 30/30\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 0.0456 - accuracy: 1.0000 - val_loss: 0.1923 - val_accuracy: 0.9663\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epochs = range(1, len(train_acc) + 1)\n",
        "\n",
        "plt.plot(epochs, train_acc, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
        "\n",
        "plt.title('Training and Validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "azGnLq9Hh7Jm",
        "outputId": "b698e819-ea1c-430b-973f-4873296393d5"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(train_loss) + 1)\n",
        "\n",
        "plt.plot(epochs, train_loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "bM9V3xV_jBHK",
        "outputId": "b85e1fb1-2ba1-427f-eb02-2b67aff7ad04"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train_ready, y_train_ready,\n",
        "                    epochs=30, batch_size=200,\n",
        "                    validation_data=(x_test_ready, y_test_ready))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQzgc73mO76-",
        "outputId": "4379d9dd-05d4-470b-b353-3fdd69aec017"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "8/8 [==============================] - 2s 70ms/step - loss: 1.6027 - accuracy: 0.4185 - val_loss: 1.5856 - val_accuracy: 0.5596\n",
            "Epoch 2/30\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 1.5650 - accuracy: 0.6685 - val_loss: 1.5459 - val_accuracy: 0.6427\n",
            "Epoch 3/30\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 1.5126 - accuracy: 0.7500 - val_loss: 1.4975 - val_accuracy: 0.7124\n",
            "Epoch 4/30\n",
            "8/8 [==============================] - 0s 47ms/step - loss: 1.4479 - accuracy: 0.8378 - val_loss: 1.4405 - val_accuracy: 0.7551\n",
            "Epoch 5/30\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 1.3730 - accuracy: 0.8848 - val_loss: 1.3757 - val_accuracy: 0.7798\n",
            "Epoch 6/30\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 1.2880 - accuracy: 0.9263 - val_loss: 1.3031 - val_accuracy: 0.8202\n",
            "Epoch 7/30\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 1.1935 - accuracy: 0.9473 - val_loss: 1.2233 - val_accuracy: 0.8494\n",
            "Epoch 8/30\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 1.0904 - accuracy: 0.9677 - val_loss: 1.1369 - val_accuracy: 0.8652\n",
            "Epoch 9/30\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.9813 - accuracy: 0.9747 - val_loss: 1.0464 - val_accuracy: 0.8697\n",
            "Epoch 10/30\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.8694 - accuracy: 0.9789 - val_loss: 0.9525 - val_accuracy: 0.8854\n",
            "Epoch 11/30\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.7561 - accuracy: 0.9860 - val_loss: 0.8574 - val_accuracy: 0.9034\n",
            "Epoch 12/30\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.6478 - accuracy: 0.9888 - val_loss: 0.7669 - val_accuracy: 0.9191\n",
            "Epoch 13/30\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.5493 - accuracy: 0.9923 - val_loss: 0.6822 - val_accuracy: 0.9236\n",
            "Epoch 14/30\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.4618 - accuracy: 0.9951 - val_loss: 0.6071 - val_accuracy: 0.9258\n",
            "Epoch 15/30\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 0.3867 - accuracy: 0.9972 - val_loss: 0.5406 - val_accuracy: 0.9326\n",
            "Epoch 16/30\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.3224 - accuracy: 0.9986 - val_loss: 0.4823 - val_accuracy: 0.9438\n",
            "Epoch 17/30\n",
            "8/8 [==============================] - 0s 63ms/step - loss: 0.2679 - accuracy: 0.9986 - val_loss: 0.4313 - val_accuracy: 0.9461\n",
            "Epoch 18/30\n",
            "8/8 [==============================] - 0s 62ms/step - loss: 0.2223 - accuracy: 0.9986 - val_loss: 0.3875 - val_accuracy: 0.9483\n",
            "Epoch 19/30\n",
            "8/8 [==============================] - 0s 63ms/step - loss: 0.1847 - accuracy: 0.9986 - val_loss: 0.3503 - val_accuracy: 0.9528\n",
            "Epoch 20/30\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 0.1536 - accuracy: 0.9993 - val_loss: 0.3185 - val_accuracy: 0.9640\n",
            "Epoch 21/30\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.1284 - accuracy: 1.0000 - val_loss: 0.2916 - val_accuracy: 0.9685\n",
            "Epoch 22/30\n",
            "8/8 [==============================] - 0s 48ms/step - loss: 0.1078 - accuracy: 1.0000 - val_loss: 0.2685 - val_accuracy: 0.9708\n",
            "Epoch 23/30\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 0.0913 - accuracy: 1.0000 - val_loss: 0.2485 - val_accuracy: 0.9730\n",
            "Epoch 24/30\n",
            "8/8 [==============================] - 0s 49ms/step - loss: 0.0777 - accuracy: 1.0000 - val_loss: 0.2321 - val_accuracy: 0.9730\n",
            "Epoch 25/30\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0666 - accuracy: 1.0000 - val_loss: 0.2182 - val_accuracy: 0.9730\n",
            "Epoch 26/30\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0578 - accuracy: 1.0000 - val_loss: 0.2061 - val_accuracy: 0.9730\n",
            "Epoch 27/30\n",
            "8/8 [==============================] - 0s 48ms/step - loss: 0.0506 - accuracy: 1.0000 - val_loss: 0.1960 - val_accuracy: 0.9730\n",
            "Epoch 28/30\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.0447 - accuracy: 1.0000 - val_loss: 0.1872 - val_accuracy: 0.9708\n",
            "Epoch 29/30\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.0396 - accuracy: 1.0000 - val_loss: 0.1797 - val_accuracy: 0.9708\n",
            "Epoch 30/30\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0354 - accuracy: 1.0000 - val_loss: 0.1730 - val_accuracy: 0.9730\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Generuję predykcję na testowym i przekształcam przewidywania\n",
        "#z zakodowanego formatu one-hot na etykiety\n",
        "y_predition = model.predict(x_test_ready)\n",
        "y_pred_labels = np.argmax(y_predition, axis=1)\n",
        "\n",
        "# Generuję classification raport\n",
        "report = classification_report(y_test_labels, y_pred_labels, target_names=label_encoder.classes_)\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwPZQfVOTBZt",
        "outputId": "6915ae44-f3fe-4766-db1a-325b63b3b134"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14/14 [==============================] - 0s 2ms/step\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     business       0.96      0.95      0.96       101\n",
            "entertainment       1.00      0.95      0.97        81\n",
            "     politics       0.94      0.98      0.96        83\n",
            "        sport       0.99      1.00      0.99        98\n",
            "         tech       0.98      0.99      0.98        82\n",
            "\n",
            "     accuracy                           0.97       445\n",
            "    macro avg       0.97      0.97      0.97       445\n",
            " weighted avg       0.97      0.97      0.97       445\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dokonuję wyboru reugularyzacji\n",
        "Porównałam drop out (dropout rate 0.2, 0.5) oraz L2 (0.002, 0.001 )"
      ],
      "metadata": {
        "id": "MO58UFiBAya0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*!!!! Podczas  wszystkich eksperymentów jeśli wynik val_accuracy był wyższy niż w modelu biasowym także sprawdzałam wyniki tego modelu na danych testowych, lecz nie zmieniałam nazwy validation data tylko zmieniałałam dane na testowe np.validation_data=(x_test_ready, y_test_ready)!!!!!*"
      ],
      "metadata": {
        "id": "Kn4mdW7HMCyw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DROP OUT\n",
        "*dropout rate = 0.2*"
      ],
      "metadata": {
        "id": "u9Sy-gPNZzhN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "model = Sequential([\n",
        "  Dense(16, activation='relu'),\n",
        "  Dropout(0.2),\n",
        "  Dense(16, activation='relu'),\n",
        "  Dropout(0.2),\n",
        "  Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train_ready, y_train_ready,\n",
        "epochs=30, batch_size=128,\n",
        "validation_data=(x_val_ready, y_val_ready))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7SCnDqCeKV1",
        "outputId": "99a09797-c8d7-44ea-8f5c-e4a065294b61"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "12/12 [==============================] - 3s 99ms/step - loss: 1.5966 - accuracy: 0.3673 - val_loss: 1.5675 - val_accuracy: 0.5056\n",
            "Epoch 2/30\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 1.5365 - accuracy: 0.5091 - val_loss: 1.4986 - val_accuracy: 0.5281\n",
            "Epoch 3/30\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 1.4507 - accuracy: 0.5506 - val_loss: 1.4124 - val_accuracy: 0.6152\n",
            "Epoch 4/30\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1.3533 - accuracy: 0.6187 - val_loss: 1.3113 - val_accuracy: 0.6826\n",
            "Epoch 5/30\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 1.2324 - accuracy: 0.6784 - val_loss: 1.1981 - val_accuracy: 0.6994\n",
            "Epoch 6/30\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 1.1098 - accuracy: 0.7205 - val_loss: 1.0789 - val_accuracy: 0.7388\n",
            "Epoch 7/30\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.9978 - accuracy: 0.7458 - val_loss: 0.9639 - val_accuracy: 0.7612\n",
            "Epoch 8/30\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.8863 - accuracy: 0.7591 - val_loss: 0.8592 - val_accuracy: 0.7753\n",
            "Epoch 9/30\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.7774 - accuracy: 0.7732 - val_loss: 0.7630 - val_accuracy: 0.7809\n",
            "Epoch 10/30\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.6875 - accuracy: 0.7872 - val_loss: 0.6772 - val_accuracy: 0.7865\n",
            "Epoch 11/30\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.6133 - accuracy: 0.8048 - val_loss: 0.6028 - val_accuracy: 0.7893\n",
            "Epoch 12/30\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.5412 - accuracy: 0.8237 - val_loss: 0.5393 - val_accuracy: 0.8230\n",
            "Epoch 13/30\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.4821 - accuracy: 0.8560 - val_loss: 0.4809 - val_accuracy: 0.9017\n",
            "Epoch 14/30\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.4306 - accuracy: 0.8848 - val_loss: 0.4285 - val_accuracy: 0.9410\n",
            "Epoch 15/30\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.3866 - accuracy: 0.9136 - val_loss: 0.3849 - val_accuracy: 0.9579\n",
            "Epoch 16/30\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.3353 - accuracy: 0.9354 - val_loss: 0.3443 - val_accuracy: 0.9607\n",
            "Epoch 17/30\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.3356 - accuracy: 0.9305 - val_loss: 0.3079 - val_accuracy: 0.9635\n",
            "Epoch 18/30\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.2825 - accuracy: 0.9487 - val_loss: 0.2764 - val_accuracy: 0.9691\n",
            "Epoch 19/30\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.2495 - accuracy: 0.9635 - val_loss: 0.2500 - val_accuracy: 0.9719\n",
            "Epoch 20/30\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.2354 - accuracy: 0.9537 - val_loss: 0.2264 - val_accuracy: 0.9719\n",
            "Epoch 21/30\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.2055 - accuracy: 0.9642 - val_loss: 0.2076 - val_accuracy: 0.9719\n",
            "Epoch 22/30\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.2007 - accuracy: 0.9656 - val_loss: 0.1925 - val_accuracy: 0.9691\n",
            "Epoch 23/30\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.1872 - accuracy: 0.9642 - val_loss: 0.1805 - val_accuracy: 0.9691\n",
            "Epoch 24/30\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.1709 - accuracy: 0.9705 - val_loss: 0.1695 - val_accuracy: 0.9747\n",
            "Epoch 25/30\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 0.1563 - accuracy: 0.9733 - val_loss: 0.1581 - val_accuracy: 0.9719\n",
            "Epoch 26/30\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 0.1405 - accuracy: 0.9789 - val_loss: 0.1489 - val_accuracy: 0.9691\n",
            "Epoch 27/30\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 0.1353 - accuracy: 0.9747 - val_loss: 0.1416 - val_accuracy: 0.9719\n",
            "Epoch 28/30\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 0.1223 - accuracy: 0.9810 - val_loss: 0.1344 - val_accuracy: 0.9719\n",
            "Epoch 29/30\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 0.1261 - accuracy: 0.9782 - val_loss: 0.1295 - val_accuracy: 0.9719\n",
            "Epoch 30/30\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 0.1046 - accuracy: 0.9853 - val_loss: 0.1261 - val_accuracy: 0.9691\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "model = Sequential([\n",
        "  Dense(16, activation='relu'),\n",
        "  Dropout(0.2),\n",
        "  Dense(16, activation='relu'),\n",
        "  Dropout(0.2),\n",
        "  Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train_ready, y_train_ready,\n",
        "epochs=30, batch_size=128,\n",
        "validation_data=(x_test_ready, y_test_ready))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Jq_tFJjJtZB",
        "outputId": "ed420d67-7b69-4596-9bd9-ffe899fb4807"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "12/12 [==============================] - 2s 81ms/step - loss: 1.6030 - accuracy: 0.3996 - val_loss: 1.5871 - val_accuracy: 0.8022\n",
            "Epoch 2/30\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 1.5677 - accuracy: 0.6749 - val_loss: 1.5393 - val_accuracy: 0.9056\n",
            "Epoch 3/30\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1.5050 - accuracy: 0.7669 - val_loss: 1.4729 - val_accuracy: 0.9326\n",
            "Epoch 4/30\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1.4307 - accuracy: 0.7704 - val_loss: 1.3908 - val_accuracy: 0.9438\n",
            "Epoch 5/30\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1.3338 - accuracy: 0.8020 - val_loss: 1.2923 - val_accuracy: 0.9461\n",
            "Epoch 6/30\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1.2180 - accuracy: 0.8532 - val_loss: 1.1792 - val_accuracy: 0.9461\n",
            "Epoch 7/30\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 1.0909 - accuracy: 0.8694 - val_loss: 1.0541 - val_accuracy: 0.9506\n",
            "Epoch 8/30\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 0.9723 - accuracy: 0.8778 - val_loss: 0.9278 - val_accuracy: 0.9573\n",
            "Epoch 9/30\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 0.8537 - accuracy: 0.8989 - val_loss: 0.8065 - val_accuracy: 0.9618\n",
            "Epoch 10/30\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 0.7287 - accuracy: 0.9185 - val_loss: 0.6959 - val_accuracy: 0.9618\n",
            "Epoch 11/30\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 0.6268 - accuracy: 0.9270 - val_loss: 0.5972 - val_accuracy: 0.9640\n",
            "Epoch 12/30\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 0.5422 - accuracy: 0.9347 - val_loss: 0.5132 - val_accuracy: 0.9663\n",
            "Epoch 13/30\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 0.4789 - accuracy: 0.9263 - val_loss: 0.4435 - val_accuracy: 0.9708\n",
            "Epoch 14/30\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 0.4122 - accuracy: 0.9375 - val_loss: 0.3866 - val_accuracy: 0.9708\n",
            "Epoch 15/30\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 0.3680 - accuracy: 0.9403 - val_loss: 0.3432 - val_accuracy: 0.9708\n",
            "Epoch 16/30\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 0.3472 - accuracy: 0.9389 - val_loss: 0.3047 - val_accuracy: 0.9730\n",
            "Epoch 17/30\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 0.2809 - accuracy: 0.9586 - val_loss: 0.2740 - val_accuracy: 0.9730\n",
            "Epoch 18/30\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.2622 - accuracy: 0.9565 - val_loss: 0.2473 - val_accuracy: 0.9708\n",
            "Epoch 19/30\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.2415 - accuracy: 0.9572 - val_loss: 0.2247 - val_accuracy: 0.9708\n",
            "Epoch 20/30\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.2280 - accuracy: 0.9628 - val_loss: 0.2078 - val_accuracy: 0.9708\n",
            "Epoch 21/30\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 0.2045 - accuracy: 0.9642 - val_loss: 0.1914 - val_accuracy: 0.9708\n",
            "Epoch 22/30\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 0.1774 - accuracy: 0.9684 - val_loss: 0.1801 - val_accuracy: 0.9708\n",
            "Epoch 23/30\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.1710 - accuracy: 0.9691 - val_loss: 0.1713 - val_accuracy: 0.9708\n",
            "Epoch 24/30\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.1573 - accuracy: 0.9649 - val_loss: 0.1621 - val_accuracy: 0.9685\n",
            "Epoch 25/30\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.1586 - accuracy: 0.9698 - val_loss: 0.1535 - val_accuracy: 0.9685\n",
            "Epoch 26/30\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.1363 - accuracy: 0.9740 - val_loss: 0.1465 - val_accuracy: 0.9685\n",
            "Epoch 27/30\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 0.1317 - accuracy: 0.9754 - val_loss: 0.1405 - val_accuracy: 0.9685\n",
            "Epoch 28/30\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 0.1381 - accuracy: 0.9677 - val_loss: 0.1378 - val_accuracy: 0.9685\n",
            "Epoch 29/30\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 0.1134 - accuracy: 0.9803 - val_loss: 0.1345 - val_accuracy: 0.9663\n",
            "Epoch 30/30\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.1278 - accuracy: 0.9691 - val_loss: 0.1299 - val_accuracy: 0.9663\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wyniki: val_accuracy 0.9691, lepsza niż w modelu biasowym"
      ],
      "metadata": {
        "id": "GqpKaC02FMD7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zastosowanie regularyzacji - DROP OUT 0.5"
      ],
      "metadata": {
        "id": "91lFBfSFgQpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "model = Sequential([\n",
        "Dense(16, activation='relu'),\n",
        "Dropout(0.5),\n",
        "Dense(16, activation='relu'),\n",
        "Dropout(0.5),\n",
        "Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train_ready, y_train_ready,\n",
        "epochs=30, batch_size=128,\n",
        "validation_data=(x_val_ready, y_val_ready))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEE_SuJxgPzt",
        "outputId": "cb10ddc1-6bcc-4fab-8c13-92b1abcb2879"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "12/12 [==============================] - 2s 85ms/step - loss: 1.6021 - accuracy: 0.3076 - val_loss: 1.5818 - val_accuracy: 0.5225\n",
            "Epoch 2/30\n",
            "12/12 [==============================] - 1s 47ms/step - loss: 1.5639 - accuracy: 0.3961 - val_loss: 1.5285 - val_accuracy: 0.5478\n",
            "Epoch 3/30\n",
            "12/12 [==============================] - 1s 47ms/step - loss: 1.5094 - accuracy: 0.4579 - val_loss: 1.4628 - val_accuracy: 0.6489\n",
            "Epoch 4/30\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 1.4427 - accuracy: 0.4712 - val_loss: 1.3893 - val_accuracy: 0.6601\n",
            "Epoch 5/30\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 1.3766 - accuracy: 0.5183 - val_loss: 1.3079 - val_accuracy: 0.7528\n",
            "Epoch 6/30\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 1.2992 - accuracy: 0.5358 - val_loss: 1.2202 - val_accuracy: 0.8146\n",
            "Epoch 7/30\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 1.2417 - accuracy: 0.5309 - val_loss: 1.1360 - val_accuracy: 0.8455\n",
            "Epoch 8/30\n",
            "12/12 [==============================] - 1s 74ms/step - loss: 1.1762 - accuracy: 0.5618 - val_loss: 1.0541 - val_accuracy: 0.8876\n",
            "Epoch 9/30\n",
            "12/12 [==============================] - 1s 72ms/step - loss: 1.1241 - accuracy: 0.5962 - val_loss: 0.9761 - val_accuracy: 0.9213\n",
            "Epoch 10/30\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 1.0665 - accuracy: 0.6103 - val_loss: 0.9044 - val_accuracy: 0.9326\n",
            "Epoch 11/30\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 0.9877 - accuracy: 0.6552 - val_loss: 0.8383 - val_accuracy: 0.9410\n",
            "Epoch 12/30\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 0.9498 - accuracy: 0.6510 - val_loss: 0.7740 - val_accuracy: 0.9551\n",
            "Epoch 13/30\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 0.9199 - accuracy: 0.6713 - val_loss: 0.7144 - val_accuracy: 0.9635\n",
            "Epoch 14/30\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 0.8991 - accuracy: 0.6629 - val_loss: 0.6610 - val_accuracy: 0.9607\n",
            "Epoch 15/30\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 0.8300 - accuracy: 0.7001 - val_loss: 0.6174 - val_accuracy: 0.9635\n",
            "Epoch 16/30\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.7909 - accuracy: 0.7282 - val_loss: 0.5700 - val_accuracy: 0.9691\n",
            "Epoch 17/30\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 0.7771 - accuracy: 0.7233 - val_loss: 0.5278 - val_accuracy: 0.9691\n",
            "Epoch 18/30\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 0.7329 - accuracy: 0.7212 - val_loss: 0.4908 - val_accuracy: 0.9691\n",
            "Epoch 19/30\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.7010 - accuracy: 0.7479 - val_loss: 0.4581 - val_accuracy: 0.9691\n",
            "Epoch 20/30\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 0.6986 - accuracy: 0.7669 - val_loss: 0.4277 - val_accuracy: 0.9691\n",
            "Epoch 21/30\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 0.6567 - accuracy: 0.7683 - val_loss: 0.4001 - val_accuracy: 0.9691\n",
            "Epoch 22/30\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 0.6655 - accuracy: 0.7528 - val_loss: 0.3756 - val_accuracy: 0.9747\n",
            "Epoch 23/30\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 0.6309 - accuracy: 0.7662 - val_loss: 0.3552 - val_accuracy: 0.9691\n",
            "Epoch 24/30\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 0.6061 - accuracy: 0.7767 - val_loss: 0.3350 - val_accuracy: 0.9691\n",
            "Epoch 25/30\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 0.6175 - accuracy: 0.7718 - val_loss: 0.3147 - val_accuracy: 0.9747\n",
            "Epoch 26/30\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 0.6128 - accuracy: 0.7662 - val_loss: 0.2983 - val_accuracy: 0.9775\n",
            "Epoch 27/30\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 0.5775 - accuracy: 0.7816 - val_loss: 0.2826 - val_accuracy: 0.9775\n",
            "Epoch 28/30\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 0.5526 - accuracy: 0.7879 - val_loss: 0.2687 - val_accuracy: 0.9747\n",
            "Epoch 29/30\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 0.5502 - accuracy: 0.7858 - val_loss: 0.2548 - val_accuracy: 0.9747\n",
            "Epoch 30/30\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 0.5518 - accuracy: 0.7949 - val_loss: 0.2439 - val_accuracy: 0.9747\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "model = Sequential([\n",
        "Dense(16, activation='relu'),\n",
        "Dropout(0.5),\n",
        "Dense(16, activation='relu'),\n",
        "Dropout(0.5),\n",
        "Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train_ready, y_train_ready,\n",
        "epochs=30, batch_size=128,\n",
        "validation_data=(x_test_ready, y_test_ready))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwpVPM7iLL4R",
        "outputId": "fd3a66bd-12d1-4ca6-c457-1e96c1988d1c"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "12/12 [==============================] - 2s 56ms/step - loss: 1.5996 - accuracy: 0.2823 - val_loss: 1.5761 - val_accuracy: 0.5640\n",
            "Epoch 2/30\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1.5528 - accuracy: 0.4206 - val_loss: 1.5228 - val_accuracy: 0.6247\n",
            "Epoch 3/30\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 1.4985 - accuracy: 0.4340 - val_loss: 1.4611 - val_accuracy: 0.6539\n",
            "Epoch 4/30\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1.4364 - accuracy: 0.4712 - val_loss: 1.3942 - val_accuracy: 0.6966\n",
            "Epoch 5/30\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 1.3811 - accuracy: 0.5007 - val_loss: 1.3248 - val_accuracy: 0.7393\n",
            "Epoch 6/30\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 1.3242 - accuracy: 0.4972 - val_loss: 1.2547 - val_accuracy: 0.7798\n",
            "Epoch 7/30\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 1.2506 - accuracy: 0.5463 - val_loss: 1.1823 - val_accuracy: 0.8315\n",
            "Epoch 8/30\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 1.1993 - accuracy: 0.5534 - val_loss: 1.1104 - val_accuracy: 0.8404\n",
            "Epoch 9/30\n",
            "12/12 [==============================] - 1s 48ms/step - loss: 1.1487 - accuracy: 0.5744 - val_loss: 1.0410 - val_accuracy: 0.8629\n",
            "Epoch 10/30\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1.0955 - accuracy: 0.5801 - val_loss: 0.9753 - val_accuracy: 0.8899\n",
            "Epoch 11/30\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 1.0268 - accuracy: 0.6243 - val_loss: 0.9063 - val_accuracy: 0.9101\n",
            "Epoch 12/30\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 0.9879 - accuracy: 0.6433 - val_loss: 0.8365 - val_accuracy: 0.9169\n",
            "Epoch 13/30\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 0.9487 - accuracy: 0.6468 - val_loss: 0.7718 - val_accuracy: 0.9281\n",
            "Epoch 14/30\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.9105 - accuracy: 0.6615 - val_loss: 0.7120 - val_accuracy: 0.9461\n",
            "Epoch 15/30\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.8462 - accuracy: 0.6987 - val_loss: 0.6523 - val_accuracy: 0.9461\n",
            "Epoch 16/30\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.8010 - accuracy: 0.7121 - val_loss: 0.5974 - val_accuracy: 0.9506\n",
            "Epoch 17/30\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.7696 - accuracy: 0.7247 - val_loss: 0.5487 - val_accuracy: 0.9506\n",
            "Epoch 18/30\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.7647 - accuracy: 0.7170 - val_loss: 0.5108 - val_accuracy: 0.9528\n",
            "Epoch 19/30\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.7223 - accuracy: 0.7395 - val_loss: 0.4746 - val_accuracy: 0.9506\n",
            "Epoch 20/30\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.7035 - accuracy: 0.7353 - val_loss: 0.4423 - val_accuracy: 0.9528\n",
            "Epoch 21/30\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.6762 - accuracy: 0.7486 - val_loss: 0.4150 - val_accuracy: 0.9551\n",
            "Epoch 22/30\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.6406 - accuracy: 0.7711 - val_loss: 0.3917 - val_accuracy: 0.9528\n",
            "Epoch 23/30\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.6052 - accuracy: 0.7746 - val_loss: 0.3691 - val_accuracy: 0.9551\n",
            "Epoch 24/30\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.6122 - accuracy: 0.7746 - val_loss: 0.3471 - val_accuracy: 0.9551\n",
            "Epoch 25/30\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.6148 - accuracy: 0.7718 - val_loss: 0.3291 - val_accuracy: 0.9596\n",
            "Epoch 26/30\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.5749 - accuracy: 0.7956 - val_loss: 0.3164 - val_accuracy: 0.9573\n",
            "Epoch 27/30\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.5460 - accuracy: 0.8083 - val_loss: 0.3036 - val_accuracy: 0.9573\n",
            "Epoch 28/30\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.5517 - accuracy: 0.7907 - val_loss: 0.2916 - val_accuracy: 0.9551\n",
            "Epoch 29/30\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.5218 - accuracy: 0.8125 - val_loss: 0.2768 - val_accuracy: 0.9596\n",
            "Epoch 30/30\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.5208 - accuracy: 0.8041 - val_loss: 0.2647 - val_accuracy: 0.9596\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regularyzacja L2 - Parametr 0.002"
      ],
      "metadata": {
        "id": "g4v3CIzkrmN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(16, kernel_regularizer=regularizers.l2(0.002), activation=\"relu\"),\n",
        "    Dense(16, kernel_regularizer=regularizers.l2(0.002), activation=\"relu\"),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train_ready, y_train_ready,\n",
        "                    epochs=30, batch_size=200,\n",
        "                    validation_data=(x_val_ready, y_val_ready))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCJWEZJZrxLo",
        "outputId": "0d34cd8d-1864-46ee-f9cc-a28186e96c91"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "8/8 [==============================] - 3s 112ms/step - loss: 1.6756 - accuracy: 0.4284 - val_loss: 1.6307 - val_accuracy: 0.5843\n",
            "Epoch 2/30\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 1.6059 - accuracy: 0.7247 - val_loss: 1.5826 - val_accuracy: 0.6770\n",
            "Epoch 3/30\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 1.5560 - accuracy: 0.7739 - val_loss: 1.5431 - val_accuracy: 0.7135\n",
            "Epoch 4/30\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 1.5089 - accuracy: 0.8230 - val_loss: 1.5029 - val_accuracy: 0.7303\n",
            "Epoch 5/30\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 1.4585 - accuracy: 0.8441 - val_loss: 1.4587 - val_accuracy: 0.7921\n",
            "Epoch 6/30\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 1.4047 - accuracy: 0.8729 - val_loss: 1.4116 - val_accuracy: 0.8146\n",
            "Epoch 7/30\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.3481 - accuracy: 0.9066 - val_loss: 1.3622 - val_accuracy: 0.8483\n",
            "Epoch 8/30\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 1.2891 - accuracy: 0.9319 - val_loss: 1.3098 - val_accuracy: 0.8596\n",
            "Epoch 9/30\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 1.2281 - accuracy: 0.9501 - val_loss: 1.2564 - val_accuracy: 0.8708\n",
            "Epoch 10/30\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.1653 - accuracy: 0.9551 - val_loss: 1.2017 - val_accuracy: 0.8904\n",
            "Epoch 11/30\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.1014 - accuracy: 0.9740 - val_loss: 1.1453 - val_accuracy: 0.9073\n",
            "Epoch 12/30\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.0380 - accuracy: 0.9824 - val_loss: 1.0905 - val_accuracy: 0.9157\n",
            "Epoch 13/30\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.9763 - accuracy: 0.9867 - val_loss: 1.0366 - val_accuracy: 0.9270\n",
            "Epoch 14/30\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.9174 - accuracy: 0.9916 - val_loss: 0.9855 - val_accuracy: 0.9410\n",
            "Epoch 15/30\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.8630 - accuracy: 0.9951 - val_loss: 0.9376 - val_accuracy: 0.9494\n",
            "Epoch 16/30\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.8123 - accuracy: 0.9965 - val_loss: 0.8933 - val_accuracy: 0.9522\n",
            "Epoch 17/30\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.7664 - accuracy: 0.9965 - val_loss: 0.8525 - val_accuracy: 0.9579\n",
            "Epoch 18/30\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.7247 - accuracy: 0.9965 - val_loss: 0.8154 - val_accuracy: 0.9635\n",
            "Epoch 19/30\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6881 - accuracy: 0.9972 - val_loss: 0.7815 - val_accuracy: 0.9635\n",
            "Epoch 20/30\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.6549 - accuracy: 0.9979 - val_loss: 0.7503 - val_accuracy: 0.9607\n",
            "Epoch 21/30\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6253 - accuracy: 0.9979 - val_loss: 0.7221 - val_accuracy: 0.9607\n",
            "Epoch 22/30\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.5984 - accuracy: 0.9979 - val_loss: 0.6972 - val_accuracy: 0.9663\n",
            "Epoch 23/30\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.5746 - accuracy: 0.9986 - val_loss: 0.6753 - val_accuracy: 0.9663\n",
            "Epoch 24/30\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.5530 - accuracy: 0.9986 - val_loss: 0.6548 - val_accuracy: 0.9691\n",
            "Epoch 25/30\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.5336 - accuracy: 0.9986 - val_loss: 0.6362 - val_accuracy: 0.9691\n",
            "Epoch 26/30\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.5161 - accuracy: 0.9993 - val_loss: 0.6205 - val_accuracy: 0.9719\n",
            "Epoch 27/30\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.5000 - accuracy: 0.9993 - val_loss: 0.6052 - val_accuracy: 0.9691\n",
            "Epoch 28/30\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4855 - accuracy: 0.9993 - val_loss: 0.5918 - val_accuracy: 0.9691\n",
            "Epoch 29/30\n",
            "8/8 [==============================] - 0s 63ms/step - loss: 0.4719 - accuracy: 1.0000 - val_loss: 0.5788 - val_accuracy: 0.9691\n",
            "Epoch 30/30\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 0.4596 - accuracy: 1.0000 - val_loss: 0.5664 - val_accuracy: 0.9747\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(16, kernel_regularizer=regularizers.l2(0.002), activation=\"relu\"),\n",
        "    Dense(16, kernel_regularizer=regularizers.l2(0.002), activation=\"relu\"),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train_ready, y_train_ready,\n",
        "                    epochs=30, batch_size=200,\n",
        "                    validation_data=(x_test_ready, y_test_ready))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tN25GkkSMhCe",
        "outputId": "eb04a0da-c963-4807-cdbc-f337b1aac6d3"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "8/8 [==============================] - 2s 120ms/step - loss: 1.6748 - accuracy: 0.4242 - val_loss: 1.6266 - val_accuracy: 0.6652\n",
            "Epoch 2/30\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.5963 - accuracy: 0.7956 - val_loss: 1.5690 - val_accuracy: 0.7640\n",
            "Epoch 3/30\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.5334 - accuracy: 0.8982 - val_loss: 1.5193 - val_accuracy: 0.8337\n",
            "Epoch 4/30\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 1.4731 - accuracy: 0.9452 - val_loss: 1.4679 - val_accuracy: 0.8607\n",
            "Epoch 5/30\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.4100 - accuracy: 0.9600 - val_loss: 1.4137 - val_accuracy: 0.8787\n",
            "Epoch 6/30\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.3429 - accuracy: 0.9677 - val_loss: 1.3555 - val_accuracy: 0.8989\n",
            "Epoch 7/30\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 1.2724 - accuracy: 0.9740 - val_loss: 1.2941 - val_accuracy: 0.9169\n",
            "Epoch 8/30\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.1984 - accuracy: 0.9768 - val_loss: 1.2303 - val_accuracy: 0.9281\n",
            "Epoch 9/30\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.1234 - accuracy: 0.9824 - val_loss: 1.1656 - val_accuracy: 0.9281\n",
            "Epoch 10/30\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 1.0481 - accuracy: 0.9860 - val_loss: 1.1004 - val_accuracy: 0.9393\n",
            "Epoch 11/30\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.9745 - accuracy: 0.9902 - val_loss: 1.0366 - val_accuracy: 0.9438\n",
            "Epoch 12/30\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.9044 - accuracy: 0.9916 - val_loss: 0.9767 - val_accuracy: 0.9483\n",
            "Epoch 13/30\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.8404 - accuracy: 0.9937 - val_loss: 0.9209 - val_accuracy: 0.9618\n",
            "Epoch 14/30\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.7824 - accuracy: 0.9951 - val_loss: 0.8708 - val_accuracy: 0.9685\n",
            "Epoch 15/30\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.7312 - accuracy: 0.9951 - val_loss: 0.8266 - val_accuracy: 0.9730\n",
            "Epoch 16/30\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.6856 - accuracy: 0.9965 - val_loss: 0.7877 - val_accuracy: 0.9730\n",
            "Epoch 17/30\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.6458 - accuracy: 0.9965 - val_loss: 0.7532 - val_accuracy: 0.9730\n",
            "Epoch 18/30\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.6109 - accuracy: 0.9979 - val_loss: 0.7225 - val_accuracy: 0.9708\n",
            "Epoch 19/30\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.5807 - accuracy: 0.9979 - val_loss: 0.6942 - val_accuracy: 0.9798\n",
            "Epoch 20/30\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.5539 - accuracy: 0.9979 - val_loss: 0.6699 - val_accuracy: 0.9753\n",
            "Epoch 21/30\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.5307 - accuracy: 0.9986 - val_loss: 0.6482 - val_accuracy: 0.9753\n",
            "Epoch 22/30\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.5097 - accuracy: 0.9993 - val_loss: 0.6281 - val_accuracy: 0.9798\n",
            "Epoch 23/30\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.4911 - accuracy: 0.9986 - val_loss: 0.6117 - val_accuracy: 0.9798\n",
            "Epoch 24/30\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.4742 - accuracy: 0.9993 - val_loss: 0.5956 - val_accuracy: 0.9775\n",
            "Epoch 25/30\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.4587 - accuracy: 0.9993 - val_loss: 0.5803 - val_accuracy: 0.9775\n",
            "Epoch 26/30\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.4445 - accuracy: 0.9993 - val_loss: 0.5669 - val_accuracy: 0.9775\n",
            "Epoch 27/30\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.4319 - accuracy: 1.0000 - val_loss: 0.5552 - val_accuracy: 0.9775\n",
            "Epoch 28/30\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.4201 - accuracy: 1.0000 - val_loss: 0.5435 - val_accuracy: 0.9775\n",
            "Epoch 29/30\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.4093 - accuracy: 1.0000 - val_loss: 0.5328 - val_accuracy: 0.9798\n",
            "Epoch 30/30\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.3993 - accuracy: 1.0000 - val_loss: 0.5228 - val_accuracy: 0.9798\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regularyzacja L2 - parametr 0.001"
      ],
      "metadata": {
        "id": "aWJlMxoGuhpO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(16, kernel_regularizer=regularizers.l2(0.001), activation=\"relu\"),\n",
        "    Dense(16, kernel_regularizer=regularizers.l2(0.001), activation=\"relu\"),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train_ready, y_train_ready,\n",
        "                    epochs=30, batch_size=128,\n",
        "                    validation_data=(x_val_ready, y_val_ready))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIialdy1uC3D",
        "outputId": "1be77e24-8224-4160-b626-957bcd16aea0"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "12/12 [==============================] - 3s 76ms/step - loss: 1.6297 - accuracy: 0.4108 - val_loss: 1.5882 - val_accuracy: 0.5478\n",
            "Epoch 2/30\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 1.5548 - accuracy: 0.6454 - val_loss: 1.5201 - val_accuracy: 0.6124\n",
            "Epoch 3/30\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1.4735 - accuracy: 0.7535 - val_loss: 1.4452 - val_accuracy: 0.7163\n",
            "Epoch 4/30\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1.3831 - accuracy: 0.8034 - val_loss: 1.3625 - val_accuracy: 0.7472\n",
            "Epoch 5/30\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 1.2833 - accuracy: 0.8736 - val_loss: 1.2719 - val_accuracy: 0.8090\n",
            "Epoch 6/30\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 1.1765 - accuracy: 0.9122 - val_loss: 1.1776 - val_accuracy: 0.8567\n",
            "Epoch 7/30\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 1.0674 - accuracy: 0.9473 - val_loss: 1.0840 - val_accuracy: 0.8820\n",
            "Epoch 8/30\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 0.9618 - accuracy: 0.9712 - val_loss: 0.9943 - val_accuracy: 0.9017\n",
            "Epoch 9/30\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 0.8628 - accuracy: 0.9789 - val_loss: 0.9103 - val_accuracy: 0.9242\n",
            "Epoch 10/30\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 0.7741 - accuracy: 0.9916 - val_loss: 0.8372 - val_accuracy: 0.9382\n",
            "Epoch 11/30\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.6979 - accuracy: 0.9944 - val_loss: 0.7731 - val_accuracy: 0.9494\n",
            "Epoch 12/30\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 0.6318 - accuracy: 0.9965 - val_loss: 0.7163 - val_accuracy: 0.9579\n",
            "Epoch 13/30\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 0.5766 - accuracy: 0.9979 - val_loss: 0.6689 - val_accuracy: 0.9579\n",
            "Epoch 14/30\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 0.5303 - accuracy: 0.9979 - val_loss: 0.6293 - val_accuracy: 0.9579\n",
            "Epoch 15/30\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 0.4920 - accuracy: 0.9986 - val_loss: 0.5946 - val_accuracy: 0.9607\n",
            "Epoch 16/30\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.4591 - accuracy: 0.9993 - val_loss: 0.5644 - val_accuracy: 0.9635\n",
            "Epoch 17/30\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.4311 - accuracy: 0.9993 - val_loss: 0.5376 - val_accuracy: 0.9635\n",
            "Epoch 18/30\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.4067 - accuracy: 1.0000 - val_loss: 0.5146 - val_accuracy: 0.9635\n",
            "Epoch 19/30\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.3847 - accuracy: 1.0000 - val_loss: 0.4929 - val_accuracy: 0.9663\n",
            "Epoch 20/30\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 0.3645 - accuracy: 1.0000 - val_loss: 0.4737 - val_accuracy: 0.9691\n",
            "Epoch 21/30\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 0.3465 - accuracy: 1.0000 - val_loss: 0.4559 - val_accuracy: 0.9691\n",
            "Epoch 22/30\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.3302 - accuracy: 1.0000 - val_loss: 0.4393 - val_accuracy: 0.9691\n",
            "Epoch 23/30\n",
            "12/12 [==============================] - 1s 47ms/step - loss: 0.3150 - accuracy: 1.0000 - val_loss: 0.4245 - val_accuracy: 0.9663\n",
            "Epoch 24/30\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 0.3014 - accuracy: 1.0000 - val_loss: 0.4103 - val_accuracy: 0.9663\n",
            "Epoch 25/30\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 0.2889 - accuracy: 1.0000 - val_loss: 0.3978 - val_accuracy: 0.9691\n",
            "Epoch 26/30\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 0.2777 - accuracy: 1.0000 - val_loss: 0.3859 - val_accuracy: 0.9691\n",
            "Epoch 27/30\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 0.2677 - accuracy: 1.0000 - val_loss: 0.3749 - val_accuracy: 0.9691\n",
            "Epoch 28/30\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 0.2585 - accuracy: 1.0000 - val_loss: 0.3654 - val_accuracy: 0.9691\n",
            "Epoch 29/30\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 0.2498 - accuracy: 1.0000 - val_loss: 0.3557 - val_accuracy: 0.9691\n",
            "Epoch 30/30\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 0.2418 - accuracy: 1.0000 - val_loss: 0.3479 - val_accuracy: 0.9719\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(16, kernel_regularizer=regularizers.l2(0.01), activation=\"relu\"),\n",
        "    Dense(16, kernel_regularizer=regularizers.l2(0.01), activation=\"relu\"),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train_ready, y_train_ready,\n",
        "                    epochs=30, batch_size=200,\n",
        "                    validation_data=(x_test_ready, y_test_ready))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSTf_eYpuzOD",
        "outputId": "0bfb8da2-97c1-410a-f274-f85541e2500f"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "8/8 [==============================] - 2s 120ms/step - loss: 1.9521 - accuracy: 0.2788 - val_loss: 1.7978 - val_accuracy: 0.4022\n",
            "Epoch 2/30\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.7513 - accuracy: 0.4853 - val_loss: 1.7147 - val_accuracy: 0.5056\n",
            "Epoch 3/30\n",
            "8/8 [==============================] - 0s 49ms/step - loss: 1.6940 - accuracy: 0.5829 - val_loss: 1.6887 - val_accuracy: 0.5528\n",
            "Epoch 4/30\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 1.6641 - accuracy: 0.6159 - val_loss: 1.6621 - val_accuracy: 0.5640\n",
            "Epoch 5/30\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 1.6329 - accuracy: 0.6159 - val_loss: 1.6354 - val_accuracy: 0.5685\n",
            "Epoch 6/30\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.6040 - accuracy: 0.6166 - val_loss: 1.6105 - val_accuracy: 0.5753\n",
            "Epoch 7/30\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.5759 - accuracy: 0.6215 - val_loss: 1.5858 - val_accuracy: 0.5820\n",
            "Epoch 8/30\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 1.5476 - accuracy: 0.6236 - val_loss: 1.5600 - val_accuracy: 0.5910\n",
            "Epoch 9/30\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 1.5181 - accuracy: 0.6208 - val_loss: 1.5344 - val_accuracy: 0.5888\n",
            "Epoch 10/30\n",
            "8/8 [==============================] - 1s 63ms/step - loss: 1.4882 - accuracy: 0.6271 - val_loss: 1.5076 - val_accuracy: 0.6000\n",
            "Epoch 11/30\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 1.4579 - accuracy: 0.6271 - val_loss: 1.4812 - val_accuracy: 0.6000\n",
            "Epoch 12/30\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.4274 - accuracy: 0.6341 - val_loss: 1.4542 - val_accuracy: 0.6112\n",
            "Epoch 13/30\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 1.3974 - accuracy: 0.6531 - val_loss: 1.4288 - val_accuracy: 0.6180\n",
            "Epoch 14/30\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 1.3681 - accuracy: 0.6622 - val_loss: 1.4023 - val_accuracy: 0.6449\n",
            "Epoch 15/30\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 1.3388 - accuracy: 0.6959 - val_loss: 1.3758 - val_accuracy: 0.6719\n",
            "Epoch 16/30\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 1.3100 - accuracy: 0.7479 - val_loss: 1.3511 - val_accuracy: 0.7169\n",
            "Epoch 17/30\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 1.2829 - accuracy: 0.7809 - val_loss: 1.3270 - val_accuracy: 0.7461\n",
            "Epoch 18/30\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 1.2560 - accuracy: 0.8188 - val_loss: 1.3032 - val_accuracy: 0.7910\n",
            "Epoch 19/30\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 1.2303 - accuracy: 0.8490 - val_loss: 1.2797 - val_accuracy: 0.8157\n",
            "Epoch 20/30\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 1.2050 - accuracy: 0.8813 - val_loss: 1.2556 - val_accuracy: 0.8382\n",
            "Epoch 21/30\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.1798 - accuracy: 0.8996 - val_loss: 1.2331 - val_accuracy: 0.8539\n",
            "Epoch 22/30\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.1556 - accuracy: 0.9059 - val_loss: 1.2121 - val_accuracy: 0.8674\n",
            "Epoch 23/30\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 1.1326 - accuracy: 0.9171 - val_loss: 1.1913 - val_accuracy: 0.8809\n",
            "Epoch 24/30\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 1.1097 - accuracy: 0.9396 - val_loss: 1.1715 - val_accuracy: 0.8989\n",
            "Epoch 25/30\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.0879 - accuracy: 0.9522 - val_loss: 1.1519 - val_accuracy: 0.9079\n",
            "Epoch 26/30\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 1.0678 - accuracy: 0.9614 - val_loss: 1.1339 - val_accuracy: 0.9191\n",
            "Epoch 27/30\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 1.0469 - accuracy: 0.9726 - val_loss: 1.1163 - val_accuracy: 0.9303\n",
            "Epoch 28/30\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 1.0281 - accuracy: 0.9782 - val_loss: 1.0997 - val_accuracy: 0.9371\n",
            "Epoch 29/30\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 1.0092 - accuracy: 0.9846 - val_loss: 1.0830 - val_accuracy: 0.9416\n",
            "Epoch 30/30\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.9913 - accuracy: 0.9881 - val_loss: 1.0684 - val_accuracy: 0.9506\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wnioski: Najlepsze val aaccuracy 0.9798 dla zastosowanej Regularyzacji L2 parametr 0.002 - Dlatego też tą wybrałam do modelu i dalszych eksperymentów"
      ],
      "metadata": {
        "id": "jZuN1Zo6w3in"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Eksperymenty z szerokością oraz głębokością sieci"
      ],
      "metadata": {
        "id": "J1t1oaiGxPKR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ESKPERYMENTY Z SZEROKOSCIĄ (LICZBA NEURONÓW W WARSTAWCH)\n"
      ],
      "metadata": {
        "id": "MjxMQSZBE1Gl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Na początku zwiększam ilość neuronów w 1 warstwie z 16 do 32"
      ],
      "metadata": {
        "id": "MpEa0pzlRT6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(32, kernel_regularizer=regularizers.l2(0.002), activation=\"relu\"),\n",
        "    Dense(16, kernel_regularizer=regularizers.l2(0.002), activation=\"relu\"),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train_ready, y_train_ready,\n",
        "                    epochs=30, batch_size=200,\n",
        "                    validation_data=(x_val_ready, y_val_ready))"
      ],
      "metadata": {
        "id": "215uz8bXxGtC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "697f0e66-4ec2-419f-fefb-3b110add8f1b"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "8/8 [==============================] - 3s 150ms/step - loss: 1.7261 - accuracy: 0.4431 - val_loss: 1.6482 - val_accuracy: 0.6096\n",
            "Epoch 2/30\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 1.6104 - accuracy: 0.6685 - val_loss: 1.5722 - val_accuracy: 0.6573\n",
            "Epoch 3/30\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.5370 - accuracy: 0.7100 - val_loss: 1.5166 - val_accuracy: 0.6770\n",
            "Epoch 4/30\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.4742 - accuracy: 0.7458 - val_loss: 1.4615 - val_accuracy: 0.7079\n",
            "Epoch 5/30\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.4094 - accuracy: 0.8244 - val_loss: 1.4051 - val_accuracy: 0.7640\n",
            "Epoch 6/30\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 1.3448 - accuracy: 0.8729 - val_loss: 1.3475 - val_accuracy: 0.8006\n",
            "Epoch 7/30\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 1.2798 - accuracy: 0.9150 - val_loss: 1.2909 - val_accuracy: 0.8230\n",
            "Epoch 8/30\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 1.2164 - accuracy: 0.9284 - val_loss: 1.2333 - val_accuracy: 0.8539\n",
            "Epoch 9/30\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 1.1521 - accuracy: 0.9459 - val_loss: 1.1753 - val_accuracy: 0.8624\n",
            "Epoch 10/30\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 1.0885 - accuracy: 0.9501 - val_loss: 1.1205 - val_accuracy: 0.8736\n",
            "Epoch 11/30\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 1.0267 - accuracy: 0.9628 - val_loss: 1.0658 - val_accuracy: 0.8904\n",
            "Epoch 12/30\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.9663 - accuracy: 0.9733 - val_loss: 1.0130 - val_accuracy: 0.9129\n",
            "Epoch 13/30\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 0.9081 - accuracy: 0.9810 - val_loss: 0.9614 - val_accuracy: 0.9326\n",
            "Epoch 14/30\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.8524 - accuracy: 0.9846 - val_loss: 0.9120 - val_accuracy: 0.9438\n",
            "Epoch 15/30\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.8004 - accuracy: 0.9916 - val_loss: 0.8661 - val_accuracy: 0.9494\n",
            "Epoch 16/30\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.7526 - accuracy: 0.9937 - val_loss: 0.8258 - val_accuracy: 0.9494\n",
            "Epoch 17/30\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.7095 - accuracy: 0.9958 - val_loss: 0.7879 - val_accuracy: 0.9579\n",
            "Epoch 18/30\n",
            "8/8 [==============================] - 0s 47ms/step - loss: 0.6711 - accuracy: 0.9979 - val_loss: 0.7536 - val_accuracy: 0.9579\n",
            "Epoch 19/30\n",
            "8/8 [==============================] - 0s 49ms/step - loss: 0.6366 - accuracy: 0.9986 - val_loss: 0.7231 - val_accuracy: 0.9522\n",
            "Epoch 20/30\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.6063 - accuracy: 0.9986 - val_loss: 0.6955 - val_accuracy: 0.9522\n",
            "Epoch 21/30\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 0.5799 - accuracy: 0.9986 - val_loss: 0.6713 - val_accuracy: 0.9551\n",
            "Epoch 22/30\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 0.5561 - accuracy: 0.9993 - val_loss: 0.6501 - val_accuracy: 0.9635\n",
            "Epoch 23/30\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 0.5348 - accuracy: 0.9993 - val_loss: 0.6306 - val_accuracy: 0.9691\n",
            "Epoch 24/30\n",
            "8/8 [==============================] - 0s 61ms/step - loss: 0.5157 - accuracy: 0.9986 - val_loss: 0.6129 - val_accuracy: 0.9691\n",
            "Epoch 25/30\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 0.4987 - accuracy: 0.9993 - val_loss: 0.5972 - val_accuracy: 0.9663\n",
            "Epoch 26/30\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 0.4834 - accuracy: 0.9993 - val_loss: 0.5826 - val_accuracy: 0.9747\n",
            "Epoch 27/30\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 0.4695 - accuracy: 1.0000 - val_loss: 0.5700 - val_accuracy: 0.9747\n",
            "Epoch 28/30\n",
            "8/8 [==============================] - 0s 63ms/step - loss: 0.4567 - accuracy: 0.9993 - val_loss: 0.5591 - val_accuracy: 0.9691\n",
            "Epoch 29/30\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 0.4445 - accuracy: 1.0000 - val_loss: 0.5484 - val_accuracy: 0.9719\n",
            "Epoch 30/30\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.4335 - accuracy: 1.0000 - val_loss: 0.5387 - val_accuracy: 0.9691\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(32, kernel_regularizer=regularizers.l2(0.002), activation=\"relu\"),\n",
        "    Dense(16, kernel_regularizer=regularizers.l2(0.002), activation=\"relu\"),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train_ready, y_train_ready,\n",
        "                    epochs=30, batch_size=200,\n",
        "                    validation_data=(x_test_ready, y_test_ready))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K37SGmS2RkgJ",
        "outputId": "b4dade7a-d0ac-4416-e4db-1cb66bd239df"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "8/8 [==============================] - 4s 185ms/step - loss: 1.7228 - accuracy: 0.4649 - val_loss: 1.6429 - val_accuracy: 0.7438\n",
            "Epoch 2/30\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 1.5998 - accuracy: 0.8490 - val_loss: 1.5629 - val_accuracy: 0.8517\n",
            "Epoch 3/30\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 1.5170 - accuracy: 0.9291 - val_loss: 1.5018 - val_accuracy: 0.8787\n",
            "Epoch 4/30\n",
            "8/8 [==============================] - 1s 103ms/step - loss: 1.4416 - accuracy: 0.9726 - val_loss: 1.4392 - val_accuracy: 0.9056\n",
            "Epoch 5/30\n",
            "8/8 [==============================] - 1s 115ms/step - loss: 1.3629 - accuracy: 0.9846 - val_loss: 1.3733 - val_accuracy: 0.9236\n",
            "Epoch 6/30\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 1.2802 - accuracy: 0.9902 - val_loss: 1.3020 - val_accuracy: 0.9416\n",
            "Epoch 7/30\n",
            "8/8 [==============================] - 0s 49ms/step - loss: 1.1941 - accuracy: 0.9909 - val_loss: 1.2274 - val_accuracy: 0.9483\n",
            "Epoch 8/30\n",
            "8/8 [==============================] - 0s 47ms/step - loss: 1.1058 - accuracy: 0.9937 - val_loss: 1.1518 - val_accuracy: 0.9528\n",
            "Epoch 9/30\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 1.0181 - accuracy: 0.9958 - val_loss: 1.0770 - val_accuracy: 0.9528\n",
            "Epoch 10/30\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 0.9344 - accuracy: 0.9958 - val_loss: 1.0052 - val_accuracy: 0.9573\n",
            "Epoch 11/30\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 0.8584 - accuracy: 0.9958 - val_loss: 0.9412 - val_accuracy: 0.9618\n",
            "Epoch 12/30\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.7909 - accuracy: 0.9958 - val_loss: 0.8841 - val_accuracy: 0.9618\n",
            "Epoch 13/30\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.7329 - accuracy: 0.9958 - val_loss: 0.8345 - val_accuracy: 0.9640\n",
            "Epoch 14/30\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.6838 - accuracy: 0.9972 - val_loss: 0.7911 - val_accuracy: 0.9640\n",
            "Epoch 15/30\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.6425 - accuracy: 0.9972 - val_loss: 0.7539 - val_accuracy: 0.9618\n",
            "Epoch 16/30\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.6071 - accuracy: 0.9972 - val_loss: 0.7214 - val_accuracy: 0.9640\n",
            "Epoch 17/30\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.5771 - accuracy: 0.9972 - val_loss: 0.6946 - val_accuracy: 0.9640\n",
            "Epoch 18/30\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.5514 - accuracy: 0.9979 - val_loss: 0.6713 - val_accuracy: 0.9663\n",
            "Epoch 19/30\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.5284 - accuracy: 0.9979 - val_loss: 0.6511 - val_accuracy: 0.9663\n",
            "Epoch 20/30\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.5084 - accuracy: 0.9979 - val_loss: 0.6317 - val_accuracy: 0.9663\n",
            "Epoch 21/30\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 0.4908 - accuracy: 0.9979 - val_loss: 0.6144 - val_accuracy: 0.9685\n",
            "Epoch 22/30\n",
            "8/8 [==============================] - 0s 63ms/step - loss: 0.4750 - accuracy: 0.9986 - val_loss: 0.5997 - val_accuracy: 0.9685\n",
            "Epoch 23/30\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.4609 - accuracy: 0.9993 - val_loss: 0.5871 - val_accuracy: 0.9685\n",
            "Epoch 24/30\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 0.4478 - accuracy: 0.9993 - val_loss: 0.5747 - val_accuracy: 0.9685\n",
            "Epoch 25/30\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 0.4365 - accuracy: 1.0000 - val_loss: 0.5638 - val_accuracy: 0.9708\n",
            "Epoch 26/30\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 0.4255 - accuracy: 1.0000 - val_loss: 0.5530 - val_accuracy: 0.9708\n",
            "Epoch 27/30\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 0.4157 - accuracy: 1.0000 - val_loss: 0.5429 - val_accuracy: 0.9730\n",
            "Epoch 28/30\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 0.4069 - accuracy: 1.0000 - val_loss: 0.5339 - val_accuracy: 0.9730\n",
            "Epoch 29/30\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.3981 - accuracy: 1.0000 - val_loss: 0.5259 - val_accuracy: 0.9708\n",
            "Epoch 30/30\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.3902 - accuracy: 1.0000 - val_loss: 0.5188 - val_accuracy: 0.9663\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zwiększam ilość neuronów do 32 w obu warstwach"
      ],
      "metadata": {
        "id": "qMvUL1x7FfVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(32, kernel_regularizer=regularizers.l2(0.002), activation=\"relu\"),\n",
        "    Dense(32, kernel_regularizer=regularizers.l2(0.002), activation=\"relu\"),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train_ready, y_train_ready,\n",
        "                    epochs=30, batch_size=200,\n",
        "                    validation_data=(x_val_ready, y_val_ready))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YZ4hP3XFeow",
        "outputId": "f1884aa0-7aa3-43d5-8422-986f9f6ff65d"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "8/8 [==============================] - 3s 120ms/step - loss: 1.7419 - accuracy: 0.5337 - val_loss: 1.6630 - val_accuracy: 0.7416\n",
            "Epoch 2/30\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 1.6218 - accuracy: 0.8104 - val_loss: 1.5809 - val_accuracy: 0.7725\n",
            "Epoch 3/30\n",
            "8/8 [==============================] - 1s 61ms/step - loss: 1.5376 - accuracy: 0.8406 - val_loss: 1.5134 - val_accuracy: 0.7809\n",
            "Epoch 4/30\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 1.4554 - accuracy: 0.8869 - val_loss: 1.4386 - val_accuracy: 0.8118\n",
            "Epoch 5/30\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 1.3631 - accuracy: 0.9213 - val_loss: 1.3554 - val_accuracy: 0.8343\n",
            "Epoch 6/30\n",
            "8/8 [==============================] - 0s 63ms/step - loss: 1.2620 - accuracy: 0.9368 - val_loss: 1.2647 - val_accuracy: 0.8652\n",
            "Epoch 7/30\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 1.1559 - accuracy: 0.9565 - val_loss: 1.1722 - val_accuracy: 0.8764\n",
            "Epoch 8/30\n",
            "8/8 [==============================] - 0s 61ms/step - loss: 1.0506 - accuracy: 0.9656 - val_loss: 1.0810 - val_accuracy: 0.8989\n",
            "Epoch 9/30\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 0.9492 - accuracy: 0.9768 - val_loss: 0.9942 - val_accuracy: 0.9073\n",
            "Epoch 10/30\n",
            "8/8 [==============================] - 0s 48ms/step - loss: 0.8559 - accuracy: 0.9860 - val_loss: 0.9146 - val_accuracy: 0.9185\n",
            "Epoch 11/30\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.7727 - accuracy: 0.9923 - val_loss: 0.8432 - val_accuracy: 0.9438\n",
            "Epoch 12/30\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.7012 - accuracy: 0.9937 - val_loss: 0.7814 - val_accuracy: 0.9522\n",
            "Epoch 13/30\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.6405 - accuracy: 0.9958 - val_loss: 0.7284 - val_accuracy: 0.9607\n",
            "Epoch 14/30\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.5912 - accuracy: 0.9979 - val_loss: 0.6844 - val_accuracy: 0.9635\n",
            "Epoch 15/30\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.5499 - accuracy: 0.9979 - val_loss: 0.6472 - val_accuracy: 0.9635\n",
            "Epoch 16/30\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.5169 - accuracy: 0.9986 - val_loss: 0.6173 - val_accuracy: 0.9719\n",
            "Epoch 17/30\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.4898 - accuracy: 0.9993 - val_loss: 0.5923 - val_accuracy: 0.9691\n",
            "Epoch 18/30\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 0.4664 - accuracy: 0.9993 - val_loss: 0.5707 - val_accuracy: 0.9719\n",
            "Epoch 19/30\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.4467 - accuracy: 1.0000 - val_loss: 0.5535 - val_accuracy: 0.9691\n",
            "Epoch 20/30\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.4301 - accuracy: 1.0000 - val_loss: 0.5386 - val_accuracy: 0.9719\n",
            "Epoch 21/30\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.4157 - accuracy: 1.0000 - val_loss: 0.5251 - val_accuracy: 0.9747\n",
            "Epoch 22/30\n",
            "8/8 [==============================] - 0s 49ms/step - loss: 0.4026 - accuracy: 1.0000 - val_loss: 0.5136 - val_accuracy: 0.9719\n",
            "Epoch 23/30\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 0.3913 - accuracy: 1.0000 - val_loss: 0.5034 - val_accuracy: 0.9691\n",
            "Epoch 24/30\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 0.3809 - accuracy: 1.0000 - val_loss: 0.4924 - val_accuracy: 0.9775\n",
            "Epoch 25/30\n",
            "8/8 [==============================] - 1s 63ms/step - loss: 0.3712 - accuracy: 1.0000 - val_loss: 0.4832 - val_accuracy: 0.9719\n",
            "Epoch 26/30\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.3625 - accuracy: 1.0000 - val_loss: 0.4750 - val_accuracy: 0.9719\n",
            "Epoch 27/30\n",
            "8/8 [==============================] - 1s 75ms/step - loss: 0.3546 - accuracy: 1.0000 - val_loss: 0.4664 - val_accuracy: 0.9691\n",
            "Epoch 28/30\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 0.3476 - accuracy: 1.0000 - val_loss: 0.4597 - val_accuracy: 0.9719\n",
            "Epoch 29/30\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 0.3416 - accuracy: 1.0000 - val_loss: 0.4524 - val_accuracy: 0.9719\n",
            "Epoch 30/30\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 0.3354 - accuracy: 1.0000 - val_loss: 0.4464 - val_accuracy: 0.9691\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(32, kernel_regularizer=regularizers.l2(0.002), activation=\"relu\"),\n",
        "    Dense(32, kernel_regularizer=regularizers.l2(0.002), activation=\"relu\"),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train_ready, y_train_ready,\n",
        "                    epochs=30, batch_size=200,\n",
        "                    validation_data=(x_test_ready, y_test_ready))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJBwdEdPSfII",
        "outputId": "3da3382d-3515-4394-ab23-96c1171794e2"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "8/8 [==============================] - 2s 90ms/step - loss: 1.7413 - accuracy: 0.5126 - val_loss: 1.6625 - val_accuracy: 0.6966\n",
            "Epoch 2/30\n",
            "8/8 [==============================] - 0s 49ms/step - loss: 1.6208 - accuracy: 0.7837 - val_loss: 1.5834 - val_accuracy: 0.7438\n",
            "Epoch 3/30\n",
            "8/8 [==============================] - 0s 48ms/step - loss: 1.5370 - accuracy: 0.8076 - val_loss: 1.5177 - val_accuracy: 0.7506\n",
            "Epoch 4/30\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.4544 - accuracy: 0.8279 - val_loss: 1.4441 - val_accuracy: 0.7910\n",
            "Epoch 5/30\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.3598 - accuracy: 0.8624 - val_loss: 1.3604 - val_accuracy: 0.8157\n",
            "Epoch 6/30\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.2557 - accuracy: 0.8855 - val_loss: 1.2696 - val_accuracy: 0.8337\n",
            "Epoch 7/30\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.1460 - accuracy: 0.9059 - val_loss: 1.1769 - val_accuracy: 0.8584\n",
            "Epoch 8/30\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 1.0385 - accuracy: 0.9333 - val_loss: 1.0847 - val_accuracy: 0.8854\n",
            "Epoch 9/30\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.9369 - accuracy: 0.9593 - val_loss: 0.9998 - val_accuracy: 0.9124\n",
            "Epoch 10/30\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.8453 - accuracy: 0.9733 - val_loss: 0.9245 - val_accuracy: 0.9371\n",
            "Epoch 11/30\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.7665 - accuracy: 0.9874 - val_loss: 0.8586 - val_accuracy: 0.9596\n",
            "Epoch 12/30\n",
            "8/8 [==============================] - 0s 49ms/step - loss: 0.6989 - accuracy: 0.9930 - val_loss: 0.7991 - val_accuracy: 0.9640\n",
            "Epoch 13/30\n",
            "8/8 [==============================] - 0s 47ms/step - loss: 0.6422 - accuracy: 0.9972 - val_loss: 0.7492 - val_accuracy: 0.9730\n",
            "Epoch 14/30\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.5947 - accuracy: 0.9986 - val_loss: 0.7075 - val_accuracy: 0.9753\n",
            "Epoch 15/30\n",
            "8/8 [==============================] - 0s 47ms/step - loss: 0.5553 - accuracy: 0.9986 - val_loss: 0.6722 - val_accuracy: 0.9753\n",
            "Epoch 16/30\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.5229 - accuracy: 0.9986 - val_loss: 0.6417 - val_accuracy: 0.9775\n",
            "Epoch 17/30\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.4959 - accuracy: 0.9986 - val_loss: 0.6168 - val_accuracy: 0.9775\n",
            "Epoch 18/30\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.4727 - accuracy: 0.9986 - val_loss: 0.5950 - val_accuracy: 0.9798\n",
            "Epoch 19/30\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.4533 - accuracy: 0.9979 - val_loss: 0.5766 - val_accuracy: 0.9775\n",
            "Epoch 20/30\n",
            "8/8 [==============================] - 0s 47ms/step - loss: 0.4364 - accuracy: 1.0000 - val_loss: 0.5608 - val_accuracy: 0.9775\n",
            "Epoch 21/30\n",
            "8/8 [==============================] - 0s 49ms/step - loss: 0.4213 - accuracy: 1.0000 - val_loss: 0.5455 - val_accuracy: 0.9775\n",
            "Epoch 22/30\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 0.4083 - accuracy: 1.0000 - val_loss: 0.5316 - val_accuracy: 0.9730\n",
            "Epoch 23/30\n",
            "8/8 [==============================] - 1s 73ms/step - loss: 0.3964 - accuracy: 1.0000 - val_loss: 0.5212 - val_accuracy: 0.9775\n",
            "Epoch 24/30\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 0.3854 - accuracy: 1.0000 - val_loss: 0.5095 - val_accuracy: 0.9753\n",
            "Epoch 25/30\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 0.3766 - accuracy: 1.0000 - val_loss: 0.4994 - val_accuracy: 0.9730\n",
            "Epoch 26/30\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 0.3678 - accuracy: 1.0000 - val_loss: 0.4923 - val_accuracy: 0.9708\n",
            "Epoch 27/30\n",
            "8/8 [==============================] - 1s 72ms/step - loss: 0.3601 - accuracy: 1.0000 - val_loss: 0.4852 - val_accuracy: 0.9753\n",
            "Epoch 28/30\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.3530 - accuracy: 1.0000 - val_loss: 0.4778 - val_accuracy: 0.9753\n",
            "Epoch 29/30\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 0.3461 - accuracy: 1.0000 - val_loss: 0.4701 - val_accuracy: 0.9753\n",
            "Epoch 30/30\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.3394 - accuracy: 1.0000 - val_loss: 0.4639 - val_accuracy: 0.9753\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zwiększenie liczby neuronów w 1 warstawie do 64"
      ],
      "metadata": {
        "id": "mCJnOzrnGJfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(64, kernel_regularizer=regularizers.l2(0.002), activation=\"relu\"),\n",
        "    Dense(32, kernel_regularizer=regularizers.l2(0.002), activation=\"relu\"),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train_ready, y_train_ready,\n",
        "                    epochs=30, batch_size=200,\n",
        "                    validation_data=(x_val_ready, y_val_ready))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQV4PZ7TGEyF",
        "outputId": "c200615a-9b38-4cc0-83ce-d6be2b2405a6"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "8/8 [==============================] - 3s 163ms/step - loss: 1.8351 - accuracy: 0.5246 - val_loss: 1.6805 - val_accuracy: 0.7303\n",
            "Epoch 2/30\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 1.6066 - accuracy: 0.8153 - val_loss: 1.5345 - val_accuracy: 0.7528\n",
            "Epoch 3/30\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.4628 - accuracy: 0.8624 - val_loss: 1.4227 - val_accuracy: 0.8090\n",
            "Epoch 4/30\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.3305 - accuracy: 0.9206 - val_loss: 1.3078 - val_accuracy: 0.8287\n",
            "Epoch 5/30\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 1.1959 - accuracy: 0.9558 - val_loss: 1.1928 - val_accuracy: 0.8708\n",
            "Epoch 6/30\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.0693 - accuracy: 0.9705 - val_loss: 1.0879 - val_accuracy: 0.9045\n",
            "Epoch 7/30\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 0.9550 - accuracy: 0.9860 - val_loss: 0.9928 - val_accuracy: 0.9242\n",
            "Epoch 8/30\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 0.8559 - accuracy: 0.9902 - val_loss: 0.9105 - val_accuracy: 0.9382\n",
            "Epoch 9/30\n",
            "8/8 [==============================] - 1s 72ms/step - loss: 0.7709 - accuracy: 0.9937 - val_loss: 0.8383 - val_accuracy: 0.9466\n",
            "Epoch 10/30\n",
            "8/8 [==============================] - 1s 113ms/step - loss: 0.7003 - accuracy: 0.9965 - val_loss: 0.7767 - val_accuracy: 0.9635\n",
            "Epoch 11/30\n",
            "8/8 [==============================] - 1s 107ms/step - loss: 0.6416 - accuracy: 0.9986 - val_loss: 0.7272 - val_accuracy: 0.9691\n",
            "Epoch 12/30\n",
            "8/8 [==============================] - 1s 93ms/step - loss: 0.5946 - accuracy: 0.9986 - val_loss: 0.6850 - val_accuracy: 0.9775\n",
            "Epoch 13/30\n",
            "8/8 [==============================] - 1s 116ms/step - loss: 0.5559 - accuracy: 0.9979 - val_loss: 0.6521 - val_accuracy: 0.9747\n",
            "Epoch 14/30\n",
            "8/8 [==============================] - 1s 102ms/step - loss: 0.5246 - accuracy: 0.9979 - val_loss: 0.6235 - val_accuracy: 0.9803\n",
            "Epoch 15/30\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 0.4984 - accuracy: 0.9979 - val_loss: 0.5992 - val_accuracy: 0.9747\n",
            "Epoch 16/30\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.4765 - accuracy: 0.9993 - val_loss: 0.5786 - val_accuracy: 0.9747\n",
            "Epoch 17/30\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 0.4570 - accuracy: 1.0000 - val_loss: 0.5612 - val_accuracy: 0.9719\n",
            "Epoch 18/30\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.4403 - accuracy: 1.0000 - val_loss: 0.5450 - val_accuracy: 0.9775\n",
            "Epoch 19/30\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 0.4253 - accuracy: 1.0000 - val_loss: 0.5310 - val_accuracy: 0.9747\n",
            "Epoch 20/30\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 0.4120 - accuracy: 1.0000 - val_loss: 0.5189 - val_accuracy: 0.9747\n",
            "Epoch 21/30\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 0.4009 - accuracy: 1.0000 - val_loss: 0.5082 - val_accuracy: 0.9747\n",
            "Epoch 22/30\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.3896 - accuracy: 1.0000 - val_loss: 0.4977 - val_accuracy: 0.9747\n",
            "Epoch 23/30\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.3800 - accuracy: 1.0000 - val_loss: 0.4883 - val_accuracy: 0.9747\n",
            "Epoch 24/30\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 0.3713 - accuracy: 1.0000 - val_loss: 0.4797 - val_accuracy: 0.9747\n",
            "Epoch 25/30\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.3628 - accuracy: 1.0000 - val_loss: 0.4715 - val_accuracy: 0.9747\n",
            "Epoch 26/30\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 0.3548 - accuracy: 1.0000 - val_loss: 0.4639 - val_accuracy: 0.9747\n",
            "Epoch 27/30\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 0.3477 - accuracy: 1.0000 - val_loss: 0.4578 - val_accuracy: 0.9747\n",
            "Epoch 28/30\n",
            "8/8 [==============================] - 1s 72ms/step - loss: 0.3417 - accuracy: 1.0000 - val_loss: 0.4518 - val_accuracy: 0.9747\n",
            "Epoch 29/30\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 0.3355 - accuracy: 1.0000 - val_loss: 0.4445 - val_accuracy: 0.9747\n",
            "Epoch 30/30\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 0.3301 - accuracy: 1.0000 - val_loss: 0.4375 - val_accuracy: 0.9747\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(64, kernel_regularizer=regularizers.l2(0.002), activation=\"relu\"),\n",
        "    Dense(32, kernel_regularizer=regularizers.l2(0.002), activation=\"relu\"),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train_ready, y_train_ready,\n",
        "                    epochs=30, batch_size=200,\n",
        "                    validation_data=(x_test_ready, y_test_ready))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVxdL3dUTGJJ",
        "outputId": "e81a9d00-26e4-4def-d34f-ac89ac3b86ad"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "8/8 [==============================] - 2s 126ms/step - loss: 1.8345 - accuracy: 0.4684 - val_loss: 1.6797 - val_accuracy: 0.6989\n",
            "Epoch 2/30\n",
            "8/8 [==============================] - 1s 115ms/step - loss: 1.6030 - accuracy: 0.7963 - val_loss: 1.5321 - val_accuracy: 0.7730\n",
            "Epoch 3/30\n",
            "8/8 [==============================] - 1s 98ms/step - loss: 1.4520 - accuracy: 0.8933 - val_loss: 1.4201 - val_accuracy: 0.8157\n",
            "Epoch 4/30\n",
            "8/8 [==============================] - 1s 115ms/step - loss: 1.3141 - accuracy: 0.9403 - val_loss: 1.3024 - val_accuracy: 0.8539\n",
            "Epoch 5/30\n",
            "8/8 [==============================] - 1s 117ms/step - loss: 1.1717 - accuracy: 0.9600 - val_loss: 1.1836 - val_accuracy: 0.8921\n",
            "Epoch 6/30\n",
            "8/8 [==============================] - 1s 91ms/step - loss: 1.0340 - accuracy: 0.9684 - val_loss: 1.0684 - val_accuracy: 0.9258\n",
            "Epoch 7/30\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.9075 - accuracy: 0.9895 - val_loss: 0.9617 - val_accuracy: 0.9461\n",
            "Epoch 8/30\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 0.7965 - accuracy: 0.9951 - val_loss: 0.8665 - val_accuracy: 0.9528\n",
            "Epoch 9/30\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 0.7032 - accuracy: 0.9972 - val_loss: 0.7892 - val_accuracy: 0.9573\n",
            "Epoch 10/30\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.6314 - accuracy: 0.9986 - val_loss: 0.7304 - val_accuracy: 0.9663\n",
            "Epoch 11/30\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 0.5776 - accuracy: 0.9986 - val_loss: 0.6829 - val_accuracy: 0.9730\n",
            "Epoch 12/30\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 0.5356 - accuracy: 0.9993 - val_loss: 0.6479 - val_accuracy: 0.9685\n",
            "Epoch 13/30\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 0.5032 - accuracy: 0.9993 - val_loss: 0.6172 - val_accuracy: 0.9730\n",
            "Epoch 14/30\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.4765 - accuracy: 0.9993 - val_loss: 0.5919 - val_accuracy: 0.9730\n",
            "Epoch 15/30\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 0.4542 - accuracy: 0.9993 - val_loss: 0.5719 - val_accuracy: 0.9730\n",
            "Epoch 16/30\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 0.4357 - accuracy: 0.9993 - val_loss: 0.5539 - val_accuracy: 0.9730\n",
            "Epoch 17/30\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 0.4197 - accuracy: 1.0000 - val_loss: 0.5386 - val_accuracy: 0.9730\n",
            "Epoch 18/30\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 0.4057 - accuracy: 1.0000 - val_loss: 0.5262 - val_accuracy: 0.9753\n",
            "Epoch 19/30\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.3934 - accuracy: 1.0000 - val_loss: 0.5150 - val_accuracy: 0.9730\n",
            "Epoch 20/30\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 0.3828 - accuracy: 1.0000 - val_loss: 0.5030 - val_accuracy: 0.9730\n",
            "Epoch 21/30\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 0.3725 - accuracy: 1.0000 - val_loss: 0.4929 - val_accuracy: 0.9753\n",
            "Epoch 22/30\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.3634 - accuracy: 1.0000 - val_loss: 0.4822 - val_accuracy: 0.9775\n",
            "Epoch 23/30\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 0.3548 - accuracy: 1.0000 - val_loss: 0.4759 - val_accuracy: 0.9753\n",
            "Epoch 24/30\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.3484 - accuracy: 1.0000 - val_loss: 0.4687 - val_accuracy: 0.9730\n",
            "Epoch 25/30\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 0.3414 - accuracy: 1.0000 - val_loss: 0.4596 - val_accuracy: 0.9775\n",
            "Epoch 26/30\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 0.3348 - accuracy: 1.0000 - val_loss: 0.4536 - val_accuracy: 0.9753\n",
            "Epoch 27/30\n",
            "8/8 [==============================] - 1s 90ms/step - loss: 0.3293 - accuracy: 1.0000 - val_loss: 0.4468 - val_accuracy: 0.9730\n",
            "Epoch 28/30\n",
            "8/8 [==============================] - 1s 104ms/step - loss: 0.3238 - accuracy: 1.0000 - val_loss: 0.4432 - val_accuracy: 0.9798\n",
            "Epoch 29/30\n",
            "8/8 [==============================] - 1s 105ms/step - loss: 0.3184 - accuracy: 1.0000 - val_loss: 0.4376 - val_accuracy: 0.9730\n",
            "Epoch 30/30\n",
            "8/8 [==============================] - 1s 91ms/step - loss: 0.3132 - accuracy: 1.0000 - val_loss: 0.4320 - val_accuracy: 0.9775\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(64, kernel_regularizer=regularizers.l2(0.002), activation=\"relu\"),\n",
        "    Dense(64, kernel_regularizer=regularizers.l2(0.002), activation=\"relu\"),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train_ready, y_train_ready,\n",
        "                    epochs=30, batch_size=200,\n",
        "                    validation_data=(x_val_ready, y_val_ready))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJngpbUeHNmC",
        "outputId": "f0a728d8-265b-4d72-9edf-61070c0f0aa1"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "8/8 [==============================] - 3s 194ms/step - loss: 1.8783 - accuracy: 0.5400 - val_loss: 1.7287 - val_accuracy: 0.8287\n",
            "Epoch 2/30\n",
            "8/8 [==============================] - 1s 128ms/step - loss: 1.6540 - accuracy: 0.9038 - val_loss: 1.5804 - val_accuracy: 0.8820\n",
            "Epoch 3/30\n",
            "8/8 [==============================] - 1s 126ms/step - loss: 1.4995 - accuracy: 0.9558 - val_loss: 1.4511 - val_accuracy: 0.9129\n",
            "Epoch 4/30\n",
            "8/8 [==============================] - 1s 104ms/step - loss: 1.3388 - accuracy: 0.9740 - val_loss: 1.3016 - val_accuracy: 0.9298\n",
            "Epoch 5/30\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 1.1575 - accuracy: 0.9853 - val_loss: 1.1395 - val_accuracy: 0.9551\n",
            "Epoch 6/30\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.9761 - accuracy: 0.9923 - val_loss: 0.9842 - val_accuracy: 0.9635\n",
            "Epoch 7/30\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 0.8186 - accuracy: 0.9965 - val_loss: 0.8539 - val_accuracy: 0.9691\n",
            "Epoch 8/30\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.6956 - accuracy: 0.9972 - val_loss: 0.7547 - val_accuracy: 0.9747\n",
            "Epoch 9/30\n",
            "8/8 [==============================] - 1s 75ms/step - loss: 0.6099 - accuracy: 0.9972 - val_loss: 0.6861 - val_accuracy: 0.9803\n",
            "Epoch 10/30\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 0.5498 - accuracy: 0.9972 - val_loss: 0.6359 - val_accuracy: 0.9803\n",
            "Epoch 11/30\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.5077 - accuracy: 0.9979 - val_loss: 0.5985 - val_accuracy: 0.9747\n",
            "Epoch 12/30\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.4743 - accuracy: 1.0000 - val_loss: 0.5709 - val_accuracy: 0.9747\n",
            "Epoch 13/30\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.4489 - accuracy: 0.9993 - val_loss: 0.5465 - val_accuracy: 0.9747\n",
            "Epoch 14/30\n",
            "8/8 [==============================] - 1s 89ms/step - loss: 0.4269 - accuracy: 0.9993 - val_loss: 0.5265 - val_accuracy: 0.9747\n",
            "Epoch 15/30\n",
            "8/8 [==============================] - 1s 115ms/step - loss: 0.4087 - accuracy: 1.0000 - val_loss: 0.5091 - val_accuracy: 0.9747\n",
            "Epoch 16/30\n",
            "8/8 [==============================] - 1s 92ms/step - loss: 0.3930 - accuracy: 1.0000 - val_loss: 0.4944 - val_accuracy: 0.9831\n",
            "Epoch 17/30\n",
            "8/8 [==============================] - 1s 100ms/step - loss: 0.3801 - accuracy: 1.0000 - val_loss: 0.4831 - val_accuracy: 0.9831\n",
            "Epoch 18/30\n",
            "8/8 [==============================] - 1s 118ms/step - loss: 0.3689 - accuracy: 1.0000 - val_loss: 0.4735 - val_accuracy: 0.9775\n",
            "Epoch 19/30\n",
            "8/8 [==============================] - 1s 74ms/step - loss: 0.3587 - accuracy: 1.0000 - val_loss: 0.4637 - val_accuracy: 0.9747\n",
            "Epoch 20/30\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.3486 - accuracy: 1.0000 - val_loss: 0.4532 - val_accuracy: 0.9775\n",
            "Epoch 21/30\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 0.3399 - accuracy: 1.0000 - val_loss: 0.4443 - val_accuracy: 0.9803\n",
            "Epoch 22/30\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 0.3317 - accuracy: 1.0000 - val_loss: 0.4380 - val_accuracy: 0.9747\n",
            "Epoch 23/30\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.3247 - accuracy: 1.0000 - val_loss: 0.4297 - val_accuracy: 0.9747\n",
            "Epoch 24/30\n",
            "8/8 [==============================] - 1s 62ms/step - loss: 0.3178 - accuracy: 1.0000 - val_loss: 0.4221 - val_accuracy: 0.9747\n",
            "Epoch 25/30\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 0.3114 - accuracy: 1.0000 - val_loss: 0.4164 - val_accuracy: 0.9747\n",
            "Epoch 26/30\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.3054 - accuracy: 1.0000 - val_loss: 0.4112 - val_accuracy: 0.9775\n",
            "Epoch 27/30\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 0.2997 - accuracy: 1.0000 - val_loss: 0.4055 - val_accuracy: 0.9803\n",
            "Epoch 28/30\n",
            "8/8 [==============================] - 0s 49ms/step - loss: 0.2941 - accuracy: 1.0000 - val_loss: 0.4005 - val_accuracy: 0.9747\n",
            "Epoch 29/30\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.2890 - accuracy: 1.0000 - val_loss: 0.3945 - val_accuracy: 0.9747\n",
            "Epoch 30/30\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 0.2841 - accuracy: 1.0000 - val_loss: 0.3894 - val_accuracy: 0.9803\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(64, kernel_regularizer=regularizers.l2(0.002), activation=\"relu\"),\n",
        "    Dense(64, kernel_regularizer=regularizers.l2(0.002), activation=\"relu\"),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train_ready, y_train_ready,\n",
        "                    epochs=30, batch_size=200,\n",
        "                    validation_data=(x_test_ready, y_test_ready))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnsAdYLlTm79",
        "outputId": "2387bccb-f7d1-4c7f-d3c9-a0b9cc4d488c"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "8/8 [==============================] - 3s 175ms/step - loss: 1.8820 - accuracy: 0.5414 - val_loss: 1.7380 - val_accuracy: 0.8517\n",
            "Epoch 2/30\n",
            "8/8 [==============================] - 1s 119ms/step - loss: 1.6706 - accuracy: 0.9572 - val_loss: 1.6003 - val_accuracy: 0.9393\n",
            "Epoch 3/30\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 1.5284 - accuracy: 0.9874 - val_loss: 1.4781 - val_accuracy: 0.9461\n",
            "Epoch 4/30\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 1.3727 - accuracy: 0.9909 - val_loss: 1.3298 - val_accuracy: 0.9528\n",
            "Epoch 5/30\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 1.1857 - accuracy: 0.9958 - val_loss: 1.1620 - val_accuracy: 0.9573\n",
            "Epoch 6/30\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 0.9919 - accuracy: 0.9965 - val_loss: 1.0011 - val_accuracy: 0.9596\n",
            "Epoch 7/30\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 0.8231 - accuracy: 0.9972 - val_loss: 0.8694 - val_accuracy: 0.9640\n",
            "Epoch 8/30\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 0.6961 - accuracy: 0.9972 - val_loss: 0.7709 - val_accuracy: 0.9685\n",
            "Epoch 9/30\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 0.6092 - accuracy: 0.9972 - val_loss: 0.7022 - val_accuracy: 0.9708\n",
            "Epoch 10/30\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 0.5496 - accuracy: 0.9986 - val_loss: 0.6528 - val_accuracy: 0.9753\n",
            "Epoch 11/30\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 0.5069 - accuracy: 0.9993 - val_loss: 0.6163 - val_accuracy: 0.9753\n",
            "Epoch 12/30\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 0.4744 - accuracy: 1.0000 - val_loss: 0.5867 - val_accuracy: 0.9730\n",
            "Epoch 13/30\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 0.4484 - accuracy: 0.9993 - val_loss: 0.5627 - val_accuracy: 0.9730\n",
            "Epoch 14/30\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.4272 - accuracy: 0.9993 - val_loss: 0.5443 - val_accuracy: 0.9753\n",
            "Epoch 15/30\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 0.4091 - accuracy: 1.0000 - val_loss: 0.5267 - val_accuracy: 0.9730\n",
            "Epoch 16/30\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.3941 - accuracy: 1.0000 - val_loss: 0.5119 - val_accuracy: 0.9730\n",
            "Epoch 17/30\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 0.3807 - accuracy: 1.0000 - val_loss: 0.5006 - val_accuracy: 0.9775\n",
            "Epoch 18/30\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.3689 - accuracy: 1.0000 - val_loss: 0.4874 - val_accuracy: 0.9730\n",
            "Epoch 19/30\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.3586 - accuracy: 1.0000 - val_loss: 0.4776 - val_accuracy: 0.9775\n",
            "Epoch 20/30\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.3499 - accuracy: 1.0000 - val_loss: 0.4693 - val_accuracy: 0.9730\n",
            "Epoch 21/30\n",
            "8/8 [==============================] - 0s 63ms/step - loss: 0.3415 - accuracy: 1.0000 - val_loss: 0.4617 - val_accuracy: 0.9730\n",
            "Epoch 22/30\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 0.3335 - accuracy: 1.0000 - val_loss: 0.4536 - val_accuracy: 0.9753\n",
            "Epoch 23/30\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 0.3260 - accuracy: 1.0000 - val_loss: 0.4464 - val_accuracy: 0.9730\n",
            "Epoch 24/30\n",
            "8/8 [==============================] - 2s 279ms/step - loss: 0.3194 - accuracy: 1.0000 - val_loss: 0.4395 - val_accuracy: 0.9730\n",
            "Epoch 25/30\n",
            "8/8 [==============================] - 1s 103ms/step - loss: 0.3131 - accuracy: 1.0000 - val_loss: 0.4318 - val_accuracy: 0.9730\n",
            "Epoch 26/30\n",
            "8/8 [==============================] - 1s 104ms/step - loss: 0.3072 - accuracy: 1.0000 - val_loss: 0.4257 - val_accuracy: 0.9730\n",
            "Epoch 27/30\n",
            "8/8 [==============================] - 1s 97ms/step - loss: 0.3020 - accuracy: 1.0000 - val_loss: 0.4193 - val_accuracy: 0.9730\n",
            "Epoch 28/30\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.2968 - accuracy: 1.0000 - val_loss: 0.4133 - val_accuracy: 0.9730\n",
            "Epoch 29/30\n",
            "8/8 [==============================] - 1s 75ms/step - loss: 0.2918 - accuracy: 1.0000 - val_loss: 0.4091 - val_accuracy: 0.9753\n",
            "Epoch 30/30\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.2876 - accuracy: 1.0000 - val_loss: 0.4053 - val_accuracy: 0.9730\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wnioski: Val accuracy na zbiorze testowym spadło, więc przestaję eksperymentować z szerokością sieci."
      ],
      "metadata": {
        "id": "xoPZvn9JJGM6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Najlepiej wypadła sieć o 64 neuronach w 1 warstwie oraz 32 w 2 warstwie (val_accuracy ok 98 %, więc na niej będę dokonywać dalsze eksperymenty."
      ],
      "metadata": {
        "id": "940U98l0Jn4Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Zmiany głębokości sieci"
      ],
      "metadata": {
        "id": "ERNWsb-5JenP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dodanie warstwy o 64 neuronach"
      ],
      "metadata": {
        "id": "bJYEZVcIMX5x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(64, kernel_regularizer=regularizers.l2(0.002), activation=\"relu\"),\n",
        "    Dense(64, kernel_regularizer=regularizers.l2(0.002), activation=\"relu\"),\n",
        "    Dense(32, kernel_regularizer=regularizers.l2(0.002), activation=\"relu\"),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train_ready, y_train_ready,\n",
        "                    epochs=30, batch_size=200,\n",
        "                    validation_data=(x_val_ready, y_val_ready))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGsGscBOMtDf",
        "outputId": "718bc845-dfd5-4637-d6b9-bda44bd49651"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "8/8 [==============================] - 5s 158ms/step - loss: 1.9621 - accuracy: 0.3933 - val_loss: 1.8127 - val_accuracy: 0.6376\n",
            "Epoch 2/30\n",
            "8/8 [==============================] - 1s 117ms/step - loss: 1.7429 - accuracy: 0.6840 - val_loss: 1.6666 - val_accuracy: 0.6994\n",
            "Epoch 3/30\n",
            "8/8 [==============================] - 1s 160ms/step - loss: 1.5886 - accuracy: 0.7654 - val_loss: 1.5280 - val_accuracy: 0.7360\n",
            "Epoch 4/30\n",
            "8/8 [==============================] - 1s 158ms/step - loss: 1.4134 - accuracy: 0.8111 - val_loss: 1.3565 - val_accuracy: 0.7809\n",
            "Epoch 5/30\n",
            "8/8 [==============================] - 1s 115ms/step - loss: 1.2053 - accuracy: 0.8806 - val_loss: 1.1657 - val_accuracy: 0.8961\n",
            "Epoch 6/30\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.9964 - accuracy: 0.9796 - val_loss: 0.9906 - val_accuracy: 0.9213\n",
            "Epoch 7/30\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 0.8113 - accuracy: 0.9937 - val_loss: 0.8306 - val_accuracy: 0.9579\n",
            "Epoch 8/30\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.6643 - accuracy: 0.9972 - val_loss: 0.7161 - val_accuracy: 0.9607\n",
            "Epoch 9/30\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 0.5615 - accuracy: 0.9986 - val_loss: 0.6368 - val_accuracy: 0.9747\n",
            "Epoch 10/30\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.4978 - accuracy: 0.9993 - val_loss: 0.5872 - val_accuracy: 0.9747\n",
            "Epoch 11/30\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 0.4546 - accuracy: 0.9993 - val_loss: 0.5519 - val_accuracy: 0.9747\n",
            "Epoch 12/30\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 0.4235 - accuracy: 0.9993 - val_loss: 0.5228 - val_accuracy: 0.9719\n",
            "Epoch 13/30\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.3993 - accuracy: 1.0000 - val_loss: 0.5021 - val_accuracy: 0.9775\n",
            "Epoch 14/30\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.3798 - accuracy: 1.0000 - val_loss: 0.4846 - val_accuracy: 0.9719\n",
            "Epoch 15/30\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 0.3637 - accuracy: 1.0000 - val_loss: 0.4687 - val_accuracy: 0.9803\n",
            "Epoch 16/30\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.3507 - accuracy: 1.0000 - val_loss: 0.4573 - val_accuracy: 0.9775\n",
            "Epoch 17/30\n",
            "8/8 [==============================] - 0s 49ms/step - loss: 0.3394 - accuracy: 1.0000 - val_loss: 0.4468 - val_accuracy: 0.9775\n",
            "Epoch 18/30\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 0.3294 - accuracy: 1.0000 - val_loss: 0.4363 - val_accuracy: 0.9803\n",
            "Epoch 19/30\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 0.3210 - accuracy: 1.0000 - val_loss: 0.4303 - val_accuracy: 0.9803\n",
            "Epoch 20/30\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 0.3132 - accuracy: 1.0000 - val_loss: 0.4221 - val_accuracy: 0.9747\n",
            "Epoch 21/30\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.3058 - accuracy: 1.0000 - val_loss: 0.4139 - val_accuracy: 0.9775\n",
            "Epoch 22/30\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 0.2989 - accuracy: 1.0000 - val_loss: 0.4081 - val_accuracy: 0.9803\n",
            "Epoch 23/30\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 0.2930 - accuracy: 1.0000 - val_loss: 0.4044 - val_accuracy: 0.9719\n",
            "Epoch 24/30\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 0.2874 - accuracy: 1.0000 - val_loss: 0.3973 - val_accuracy: 0.9719\n",
            "Epoch 25/30\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.2826 - accuracy: 1.0000 - val_loss: 0.3955 - val_accuracy: 0.9719\n",
            "Epoch 26/30\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 0.2779 - accuracy: 1.0000 - val_loss: 0.3913 - val_accuracy: 0.9747\n",
            "Epoch 27/30\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.2731 - accuracy: 1.0000 - val_loss: 0.3862 - val_accuracy: 0.9663\n",
            "Epoch 28/30\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.2684 - accuracy: 1.0000 - val_loss: 0.3801 - val_accuracy: 0.9691\n",
            "Epoch 29/30\n",
            "8/8 [==============================] - 1s 81ms/step - loss: 0.2642 - accuracy: 1.0000 - val_loss: 0.3797 - val_accuracy: 0.9719\n",
            "Epoch 30/30\n",
            "8/8 [==============================] - 1s 87ms/step - loss: 0.2607 - accuracy: 1.0000 - val_loss: 0.3763 - val_accuracy: 0.9719\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wnioski: Ponownie val Accuracy 0.9719 słabsze niż w modelu wybranym powyżej, więc nie ma sensu sprawdzać na danych testowych."
      ],
      "metadata": {
        "id": "7ZzjdKd6V_R3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dodanie warstwy 128 neuronów"
      ],
      "metadata": {
        "id": "-vJBmAfAXe1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(128, kernel_regularizer=regularizers.l2(0.002), activation=\"relu\"),\n",
        "    Dense(64, kernel_regularizer=regularizers.l2(0.002), activation=\"relu\"),\n",
        "    Dense(32, kernel_regularizer=regularizers.l2(0.002), activation=\"relu\"),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train_ready, y_train_ready,\n",
        "                    epochs=30, batch_size=200,\n",
        "                    validation_data=(x_val_ready, y_val_ready))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXUfHwU0kT62",
        "outputId": "e83fac6c-1b70-47f1-e756-4f3f3aee53a1"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "8/8 [==============================] - 9s 339ms/step - loss: 2.1578 - accuracy: 0.4853 - val_loss: 1.8900 - val_accuracy: 0.6404\n",
            "Epoch 2/30\n",
            "8/8 [==============================] - 1s 175ms/step - loss: 1.7881 - accuracy: 0.7437 - val_loss: 1.6710 - val_accuracy: 0.7809\n",
            "Epoch 3/30\n",
            "8/8 [==============================] - 1s 102ms/step - loss: 1.5789 - accuracy: 0.8933 - val_loss: 1.4886 - val_accuracy: 0.8287\n",
            "Epoch 4/30\n",
            "8/8 [==============================] - 1s 104ms/step - loss: 1.3576 - accuracy: 0.9361 - val_loss: 1.2752 - val_accuracy: 0.8848\n",
            "Epoch 5/30\n",
            "8/8 [==============================] - 1s 123ms/step - loss: 1.1168 - accuracy: 0.9740 - val_loss: 1.0662 - val_accuracy: 0.9185\n",
            "Epoch 6/30\n",
            "8/8 [==============================] - 1s 162ms/step - loss: 0.8983 - accuracy: 0.9888 - val_loss: 0.8920 - val_accuracy: 0.9382\n",
            "Epoch 7/30\n",
            "8/8 [==============================] - 1s 165ms/step - loss: 0.7224 - accuracy: 0.9986 - val_loss: 0.7549 - val_accuracy: 0.9691\n",
            "Epoch 8/30\n",
            "8/8 [==============================] - 1s 161ms/step - loss: 0.6058 - accuracy: 0.9986 - val_loss: 0.6645 - val_accuracy: 0.9663\n",
            "Epoch 9/30\n",
            "8/8 [==============================] - 1s 89ms/step - loss: 0.5328 - accuracy: 0.9986 - val_loss: 0.6068 - val_accuracy: 0.9719\n",
            "Epoch 10/30\n",
            "8/8 [==============================] - 1s 81ms/step - loss: 0.4823 - accuracy: 0.9993 - val_loss: 0.5661 - val_accuracy: 0.9747\n",
            "Epoch 11/30\n",
            "8/8 [==============================] - 1s 104ms/step - loss: 0.4469 - accuracy: 1.0000 - val_loss: 0.5363 - val_accuracy: 0.9691\n",
            "Epoch 12/30\n",
            "8/8 [==============================] - 1s 102ms/step - loss: 0.4191 - accuracy: 1.0000 - val_loss: 0.5118 - val_accuracy: 0.9691\n",
            "Epoch 13/30\n",
            "8/8 [==============================] - 1s 93ms/step - loss: 0.3978 - accuracy: 1.0000 - val_loss: 0.4948 - val_accuracy: 0.9691\n",
            "Epoch 14/30\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 0.3812 - accuracy: 1.0000 - val_loss: 0.4778 - val_accuracy: 0.9691\n",
            "Epoch 15/30\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 0.3654 - accuracy: 1.0000 - val_loss: 0.4629 - val_accuracy: 0.9747\n",
            "Epoch 16/30\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 0.3524 - accuracy: 1.0000 - val_loss: 0.4509 - val_accuracy: 0.9747\n",
            "Epoch 17/30\n",
            "8/8 [==============================] - 1s 100ms/step - loss: 0.3400 - accuracy: 1.0000 - val_loss: 0.4403 - val_accuracy: 0.9691\n",
            "Epoch 18/30\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 0.3301 - accuracy: 1.0000 - val_loss: 0.4292 - val_accuracy: 0.9719\n",
            "Epoch 19/30\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 0.3215 - accuracy: 1.0000 - val_loss: 0.4221 - val_accuracy: 0.9719\n",
            "Epoch 20/30\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 0.3141 - accuracy: 1.0000 - val_loss: 0.4142 - val_accuracy: 0.9663\n",
            "Epoch 21/30\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 0.3057 - accuracy: 1.0000 - val_loss: 0.4071 - val_accuracy: 0.9663\n",
            "Epoch 22/30\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 0.2979 - accuracy: 1.0000 - val_loss: 0.4005 - val_accuracy: 0.9691\n",
            "Epoch 23/30\n",
            "8/8 [==============================] - 1s 117ms/step - loss: 0.2905 - accuracy: 1.0000 - val_loss: 0.3938 - val_accuracy: 0.9635\n",
            "Epoch 24/30\n",
            "8/8 [==============================] - 1s 145ms/step - loss: 0.2844 - accuracy: 1.0000 - val_loss: 0.3884 - val_accuracy: 0.9663\n",
            "Epoch 25/30\n",
            "8/8 [==============================] - 1s 167ms/step - loss: 0.2787 - accuracy: 1.0000 - val_loss: 0.3832 - val_accuracy: 0.9663\n",
            "Epoch 26/30\n",
            "8/8 [==============================] - 1s 141ms/step - loss: 0.2734 - accuracy: 1.0000 - val_loss: 0.3765 - val_accuracy: 0.9635\n",
            "Epoch 27/30\n",
            "8/8 [==============================] - 1s 96ms/step - loss: 0.2684 - accuracy: 1.0000 - val_loss: 0.3706 - val_accuracy: 0.9635\n",
            "Epoch 28/30\n",
            "8/8 [==============================] - 1s 100ms/step - loss: 0.2640 - accuracy: 1.0000 - val_loss: 0.3648 - val_accuracy: 0.9663\n",
            "Epoch 29/30\n",
            "8/8 [==============================] - 1s 100ms/step - loss: 0.2611 - accuracy: 1.0000 - val_loss: 0.3596 - val_accuracy: 0.9663\n",
            "Epoch 30/30\n",
            "8/8 [==============================] - 1s 97ms/step - loss: 0.2568 - accuracy: 1.0000 - val_loss: 0.3567 - val_accuracy: 0.9691\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wnioski: Val_accuracy takie jak w modelu referencyjnym, dlatego przestaję już dodawać warstwy."
      ],
      "metadata": {
        "id": "LKywB3pEXGgG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usunięcie 1 warstwy o 64 neuronach"
      ],
      "metadata": {
        "id": "jlDB6ab0Nis-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(32, kernel_regularizer=regularizers.l2(0.002), activation=\"relu\"),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train_ready, y_train_ready,\n",
        "                    epochs=30, batch_size=200,\n",
        "                    validation_data=(x_val_ready, y_val_ready))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHHs9dX3NlnL",
        "outputId": "522a9cf2-78cf-49e9-df32-de01be666a8f"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "8/8 [==============================] - 5s 137ms/step - loss: 1.6714 - accuracy: 0.5878 - val_loss: 1.5747 - val_accuracy: 0.8258\n",
            "Epoch 2/30\n",
            "8/8 [==============================] - 1s 87ms/step - loss: 1.5190 - accuracy: 0.9052 - val_loss: 1.4755 - val_accuracy: 0.8792\n",
            "Epoch 3/30\n",
            "8/8 [==============================] - 1s 74ms/step - loss: 1.4189 - accuracy: 0.9487 - val_loss: 1.4056 - val_accuracy: 0.8989\n",
            "Epoch 4/30\n",
            "8/8 [==============================] - 1s 139ms/step - loss: 1.3398 - accuracy: 0.9684 - val_loss: 1.3447 - val_accuracy: 0.9157\n",
            "Epoch 5/30\n",
            "8/8 [==============================] - 1s 108ms/step - loss: 1.2698 - accuracy: 0.9782 - val_loss: 1.2885 - val_accuracy: 0.9270\n",
            "Epoch 6/30\n",
            "8/8 [==============================] - 1s 91ms/step - loss: 1.2065 - accuracy: 0.9860 - val_loss: 1.2358 - val_accuracy: 0.9326\n",
            "Epoch 7/30\n",
            "8/8 [==============================] - 1s 159ms/step - loss: 1.1491 - accuracy: 0.9874 - val_loss: 1.1867 - val_accuracy: 0.9466\n",
            "Epoch 8/30\n",
            "8/8 [==============================] - 1s 179ms/step - loss: 1.0963 - accuracy: 0.9888 - val_loss: 1.1419 - val_accuracy: 0.9466\n",
            "Epoch 9/30\n",
            "8/8 [==============================] - 3s 398ms/step - loss: 1.0478 - accuracy: 0.9895 - val_loss: 1.0992 - val_accuracy: 0.9466\n",
            "Epoch 10/30\n",
            "8/8 [==============================] - 1s 117ms/step - loss: 1.0024 - accuracy: 0.9923 - val_loss: 1.0597 - val_accuracy: 0.9494\n",
            "Epoch 11/30\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 0.9612 - accuracy: 0.9937 - val_loss: 1.0230 - val_accuracy: 0.9579\n",
            "Epoch 12/30\n",
            "8/8 [==============================] - 1s 72ms/step - loss: 0.9235 - accuracy: 0.9944 - val_loss: 0.9901 - val_accuracy: 0.9607\n",
            "Epoch 13/30\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 0.8892 - accuracy: 0.9944 - val_loss: 0.9595 - val_accuracy: 0.9579\n",
            "Epoch 14/30\n",
            "8/8 [==============================] - 1s 63ms/step - loss: 0.8580 - accuracy: 0.9951 - val_loss: 0.9309 - val_accuracy: 0.9635\n",
            "Epoch 15/30\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 0.8294 - accuracy: 0.9958 - val_loss: 0.9045 - val_accuracy: 0.9691\n",
            "Epoch 16/30\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.8034 - accuracy: 0.9958 - val_loss: 0.8814 - val_accuracy: 0.9691\n",
            "Epoch 17/30\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.7800 - accuracy: 0.9951 - val_loss: 0.8603 - val_accuracy: 0.9663\n",
            "Epoch 18/30\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 0.7578 - accuracy: 0.9951 - val_loss: 0.8404 - val_accuracy: 0.9691\n",
            "Epoch 19/30\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 0.7379 - accuracy: 0.9958 - val_loss: 0.8226 - val_accuracy: 0.9691\n",
            "Epoch 20/30\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.7193 - accuracy: 0.9965 - val_loss: 0.8055 - val_accuracy: 0.9719\n",
            "Epoch 21/30\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.7020 - accuracy: 0.9972 - val_loss: 0.7895 - val_accuracy: 0.9747\n",
            "Epoch 22/30\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.6860 - accuracy: 0.9965 - val_loss: 0.7746 - val_accuracy: 0.9747\n",
            "Epoch 23/30\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.6709 - accuracy: 0.9965 - val_loss: 0.7605 - val_accuracy: 0.9747\n",
            "Epoch 24/30\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.6572 - accuracy: 0.9965 - val_loss: 0.7472 - val_accuracy: 0.9747\n",
            "Epoch 25/30\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.6442 - accuracy: 0.9965 - val_loss: 0.7354 - val_accuracy: 0.9747\n",
            "Epoch 26/30\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.6320 - accuracy: 0.9965 - val_loss: 0.7238 - val_accuracy: 0.9747\n",
            "Epoch 27/30\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.6204 - accuracy: 0.9972 - val_loss: 0.7137 - val_accuracy: 0.9775\n",
            "Epoch 28/30\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.6096 - accuracy: 0.9972 - val_loss: 0.7033 - val_accuracy: 0.9775\n",
            "Epoch 29/30\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.5990 - accuracy: 0.9972 - val_loss: 0.6936 - val_accuracy: 0.9775\n",
            "Epoch 30/30\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.5895 - accuracy: 0.9972 - val_loss: 0.6849 - val_accuracy: 0.9747\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(32, kernel_regularizer=regularizers.l2(0.002), activation=\"relu\"),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train_ready, y_train_ready,\n",
        "                    epochs=30, batch_size=200,\n",
        "                    validation_data=(x_test_ready, y_test_ready))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiqgcOWIYLAj",
        "outputId": "f93b54af-4ecd-4236-f44f-b46c72c7867f"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "8/8 [==============================] - 2s 118ms/step - loss: 1.6695 - accuracy: 0.4607 - val_loss: 1.5732 - val_accuracy: 0.6337\n",
            "Epoch 2/30\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 1.5146 - accuracy: 0.7669 - val_loss: 1.4732 - val_accuracy: 0.6719\n",
            "Epoch 3/30\n",
            "8/8 [==============================] - 1s 94ms/step - loss: 1.4126 - accuracy: 0.8301 - val_loss: 1.4053 - val_accuracy: 0.7079\n",
            "Epoch 4/30\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 1.3352 - accuracy: 0.8694 - val_loss: 1.3491 - val_accuracy: 0.7393\n",
            "Epoch 5/30\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 1.2684 - accuracy: 0.8989 - val_loss: 1.2987 - val_accuracy: 0.7798\n",
            "Epoch 6/30\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 1.2102 - accuracy: 0.9171 - val_loss: 1.2530 - val_accuracy: 0.8045\n",
            "Epoch 7/30\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.1585 - accuracy: 0.9340 - val_loss: 1.2115 - val_accuracy: 0.8135\n",
            "Epoch 8/30\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 1.1116 - accuracy: 0.9445 - val_loss: 1.1732 - val_accuracy: 0.8427\n",
            "Epoch 9/30\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.0686 - accuracy: 0.9544 - val_loss: 1.1367 - val_accuracy: 0.8697\n",
            "Epoch 10/30\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 1.0286 - accuracy: 0.9635 - val_loss: 1.1022 - val_accuracy: 0.8876\n",
            "Epoch 11/30\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.9918 - accuracy: 0.9705 - val_loss: 1.0696 - val_accuracy: 0.8989\n",
            "Epoch 12/30\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.9569 - accuracy: 0.9775 - val_loss: 1.0389 - val_accuracy: 0.9146\n",
            "Epoch 13/30\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.9252 - accuracy: 0.9824 - val_loss: 1.0110 - val_accuracy: 0.9191\n",
            "Epoch 14/30\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.8953 - accuracy: 0.9874 - val_loss: 0.9847 - val_accuracy: 0.9281\n",
            "Epoch 15/30\n",
            "8/8 [==============================] - 0s 48ms/step - loss: 0.8675 - accuracy: 0.9888 - val_loss: 0.9596 - val_accuracy: 0.9303\n",
            "Epoch 16/30\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 0.8416 - accuracy: 0.9909 - val_loss: 0.9363 - val_accuracy: 0.9371\n",
            "Epoch 17/30\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 0.8171 - accuracy: 0.9930 - val_loss: 0.9149 - val_accuracy: 0.9393\n",
            "Epoch 18/30\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 0.7945 - accuracy: 0.9937 - val_loss: 0.8947 - val_accuracy: 0.9393\n",
            "Epoch 19/30\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 0.7733 - accuracy: 0.9951 - val_loss: 0.8759 - val_accuracy: 0.9461\n",
            "Epoch 20/30\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 0.7533 - accuracy: 0.9958 - val_loss: 0.8581 - val_accuracy: 0.9461\n",
            "Epoch 21/30\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 0.7348 - accuracy: 0.9958 - val_loss: 0.8410 - val_accuracy: 0.9483\n",
            "Epoch 22/30\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 0.7174 - accuracy: 0.9958 - val_loss: 0.8251 - val_accuracy: 0.9528\n",
            "Epoch 23/30\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 0.7009 - accuracy: 0.9965 - val_loss: 0.8102 - val_accuracy: 0.9528\n",
            "Epoch 24/30\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 0.6857 - accuracy: 0.9965 - val_loss: 0.7959 - val_accuracy: 0.9528\n",
            "Epoch 25/30\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 0.6717 - accuracy: 0.9972 - val_loss: 0.7810 - val_accuracy: 0.9596\n",
            "Epoch 26/30\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.6581 - accuracy: 0.9979 - val_loss: 0.7684 - val_accuracy: 0.9506\n",
            "Epoch 27/30\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.6456 - accuracy: 0.9979 - val_loss: 0.7564 - val_accuracy: 0.9551\n",
            "Epoch 28/30\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.6336 - accuracy: 0.9979 - val_loss: 0.7446 - val_accuracy: 0.9596\n",
            "Epoch 29/30\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.6223 - accuracy: 0.9979 - val_loss: 0.7333 - val_accuracy: 0.9573\n",
            "Epoch 30/30\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.6117 - accuracy: 0.9972 - val_loss: 0.7230 - val_accuracy: 0.9596\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usunięcie warstwy o 32 neuronach"
      ],
      "metadata": {
        "id": "L43dNo0NEBdQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(64, kernel_regularizer=regularizers.l2(0.002), activation=\"relu\"),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train_ready, y_train_ready,\n",
        "                    epochs=30, batch_size=200,\n",
        "                    validation_data=(x_train_ready, y_train_ready))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHaIk0xdZbv5",
        "outputId": "d53c195d-6952-4ee1-80e7-6e9ec1d9ab11"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "8/8 [==============================] - 2s 164ms/step - loss: 1.7456 - accuracy: 0.5646 - val_loss: 1.5679 - val_accuracy: 0.8631\n",
            "Epoch 2/30\n",
            "8/8 [==============================] - 1s 142ms/step - loss: 1.5030 - accuracy: 0.8757 - val_loss: 1.4064 - val_accuracy: 0.9277\n",
            "Epoch 3/30\n",
            "8/8 [==============================] - 1s 139ms/step - loss: 1.3687 - accuracy: 0.9312 - val_loss: 1.3019 - val_accuracy: 0.9494\n",
            "Epoch 4/30\n",
            "8/8 [==============================] - 1s 145ms/step - loss: 1.2714 - accuracy: 0.9529 - val_loss: 1.2137 - val_accuracy: 0.9621\n",
            "Epoch 5/30\n",
            "8/8 [==============================] - 1s 128ms/step - loss: 1.1875 - accuracy: 0.9649 - val_loss: 1.1366 - val_accuracy: 0.9740\n",
            "Epoch 6/30\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 1.1148 - accuracy: 0.9747 - val_loss: 1.0696 - val_accuracy: 0.9846\n",
            "Epoch 7/30\n",
            "8/8 [==============================] - 1s 105ms/step - loss: 1.0508 - accuracy: 0.9860 - val_loss: 1.0104 - val_accuracy: 0.9881\n",
            "Epoch 8/30\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 0.9940 - accuracy: 0.9881 - val_loss: 0.9575 - val_accuracy: 0.9902\n",
            "Epoch 9/30\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 0.9434 - accuracy: 0.9909 - val_loss: 0.9106 - val_accuracy: 0.9930\n",
            "Epoch 10/30\n",
            "8/8 [==============================] - 1s 106ms/step - loss: 0.8983 - accuracy: 0.9937 - val_loss: 0.8687 - val_accuracy: 0.9944\n",
            "Epoch 11/30\n",
            "8/8 [==============================] - 1s 144ms/step - loss: 0.8582 - accuracy: 0.9930 - val_loss: 0.8309 - val_accuracy: 0.9958\n",
            "Epoch 12/30\n",
            "8/8 [==============================] - 1s 144ms/step - loss: 0.8218 - accuracy: 0.9951 - val_loss: 0.7972 - val_accuracy: 0.9972\n",
            "Epoch 13/30\n",
            "8/8 [==============================] - 1s 121ms/step - loss: 0.7893 - accuracy: 0.9972 - val_loss: 0.7666 - val_accuracy: 0.9972\n",
            "Epoch 14/30\n",
            "8/8 [==============================] - 1s 124ms/step - loss: 0.7596 - accuracy: 0.9958 - val_loss: 0.7390 - val_accuracy: 0.9958\n",
            "Epoch 15/30\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 0.7335 - accuracy: 0.9951 - val_loss: 0.7146 - val_accuracy: 0.9958\n",
            "Epoch 16/30\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 0.7099 - accuracy: 0.9958 - val_loss: 0.6923 - val_accuracy: 0.9965\n",
            "Epoch 17/30\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.6880 - accuracy: 0.9965 - val_loss: 0.6720 - val_accuracy: 0.9965\n",
            "Epoch 18/30\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 0.6686 - accuracy: 0.9965 - val_loss: 0.6532 - val_accuracy: 0.9965\n",
            "Epoch 19/30\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.6499 - accuracy: 0.9965 - val_loss: 0.6360 - val_accuracy: 0.9965\n",
            "Epoch 20/30\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.6337 - accuracy: 0.9965 - val_loss: 0.6203 - val_accuracy: 0.9965\n",
            "Epoch 21/30\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 0.6184 - accuracy: 0.9965 - val_loss: 0.6057 - val_accuracy: 0.9972\n",
            "Epoch 22/30\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 0.6038 - accuracy: 0.9972 - val_loss: 0.5918 - val_accuracy: 0.9972\n",
            "Epoch 23/30\n",
            "8/8 [==============================] - 1s 101ms/step - loss: 0.5905 - accuracy: 0.9979 - val_loss: 0.5790 - val_accuracy: 0.9979\n",
            "Epoch 24/30\n",
            "8/8 [==============================] - 1s 103ms/step - loss: 0.5781 - accuracy: 0.9979 - val_loss: 0.5675 - val_accuracy: 0.9972\n",
            "Epoch 25/30\n",
            "8/8 [==============================] - 1s 103ms/step - loss: 0.5667 - accuracy: 0.9972 - val_loss: 0.5562 - val_accuracy: 0.9972\n",
            "Epoch 26/30\n",
            "8/8 [==============================] - 1s 107ms/step - loss: 0.5555 - accuracy: 0.9972 - val_loss: 0.5454 - val_accuracy: 0.9972\n",
            "Epoch 27/30\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 0.5450 - accuracy: 0.9972 - val_loss: 0.5353 - val_accuracy: 0.9972\n",
            "Epoch 28/30\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.5351 - accuracy: 0.9972 - val_loss: 0.5259 - val_accuracy: 0.9972\n",
            "Epoch 29/30\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.5260 - accuracy: 0.9972 - val_loss: 0.5171 - val_accuracy: 0.9979\n",
            "Epoch 30/30\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.5170 - accuracy: 0.9979 - val_loss: 0.5085 - val_accuracy: 0.9979\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(64, kernel_regularizer=regularizers.l2(0.002), activation=\"relu\"),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train_ready, y_train_ready,\n",
        "                    epochs=30, batch_size=200,\n",
        "                    validation_data=(x_test_ready, y_test_ready))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gwa0O7q3amF9",
        "outputId": "ffaf7127-1ea6-4b6a-f898-94a5ccf5164a"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "8/8 [==============================] - 3s 187ms/step - loss: 1.7472 - accuracy: 0.5815 - val_loss: 1.5897 - val_accuracy: 0.8899\n",
            "Epoch 2/30\n",
            "8/8 [==============================] - 1s 73ms/step - loss: 1.5096 - accuracy: 0.9607 - val_loss: 1.4506 - val_accuracy: 0.9281\n",
            "Epoch 3/30\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.3755 - accuracy: 0.9782 - val_loss: 1.3644 - val_accuracy: 0.9371\n",
            "Epoch 4/30\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 1.2763 - accuracy: 0.9895 - val_loss: 1.2898 - val_accuracy: 0.9393\n",
            "Epoch 5/30\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.1890 - accuracy: 0.9888 - val_loss: 1.2219 - val_accuracy: 0.9416\n",
            "Epoch 6/30\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.1124 - accuracy: 0.9902 - val_loss: 1.1603 - val_accuracy: 0.9461\n",
            "Epoch 7/30\n",
            "8/8 [==============================] - 0s 62ms/step - loss: 1.0444 - accuracy: 0.9916 - val_loss: 1.1045 - val_accuracy: 0.9483\n",
            "Epoch 8/30\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.9845 - accuracy: 0.9923 - val_loss: 1.0543 - val_accuracy: 0.9506\n",
            "Epoch 9/30\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.9312 - accuracy: 0.9937 - val_loss: 1.0099 - val_accuracy: 0.9506\n",
            "Epoch 10/30\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 0.8853 - accuracy: 0.9944 - val_loss: 0.9696 - val_accuracy: 0.9528\n",
            "Epoch 11/30\n",
            "8/8 [==============================] - 1s 74ms/step - loss: 0.8438 - accuracy: 0.9951 - val_loss: 0.9345 - val_accuracy: 0.9573\n",
            "Epoch 12/30\n",
            "8/8 [==============================] - 1s 74ms/step - loss: 0.8079 - accuracy: 0.9944 - val_loss: 0.9031 - val_accuracy: 0.9573\n",
            "Epoch 13/30\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 0.7761 - accuracy: 0.9951 - val_loss: 0.8745 - val_accuracy: 0.9596\n",
            "Epoch 14/30\n",
            "8/8 [==============================] - 1s 91ms/step - loss: 0.7471 - accuracy: 0.9958 - val_loss: 0.8493 - val_accuracy: 0.9596\n",
            "Epoch 15/30\n",
            "8/8 [==============================] - 1s 98ms/step - loss: 0.7214 - accuracy: 0.9958 - val_loss: 0.8249 - val_accuracy: 0.9596\n",
            "Epoch 16/30\n",
            "8/8 [==============================] - 1s 127ms/step - loss: 0.6983 - accuracy: 0.9972 - val_loss: 0.8035 - val_accuracy: 0.9640\n",
            "Epoch 17/30\n",
            "8/8 [==============================] - 1s 107ms/step - loss: 0.6777 - accuracy: 0.9979 - val_loss: 0.7858 - val_accuracy: 0.9618\n",
            "Epoch 18/30\n",
            "8/8 [==============================] - 1s 111ms/step - loss: 0.6586 - accuracy: 0.9979 - val_loss: 0.7677 - val_accuracy: 0.9618\n",
            "Epoch 19/30\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 0.6407 - accuracy: 0.9979 - val_loss: 0.7517 - val_accuracy: 0.9618\n",
            "Epoch 20/30\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.6241 - accuracy: 0.9979 - val_loss: 0.7366 - val_accuracy: 0.9618\n",
            "Epoch 21/30\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 0.6091 - accuracy: 0.9979 - val_loss: 0.7221 - val_accuracy: 0.9618\n",
            "Epoch 22/30\n",
            "8/8 [==============================] - 1s 73ms/step - loss: 0.5953 - accuracy: 0.9986 - val_loss: 0.7094 - val_accuracy: 0.9618\n",
            "Epoch 23/30\n",
            "8/8 [==============================] - 1s 87ms/step - loss: 0.5822 - accuracy: 0.9979 - val_loss: 0.6958 - val_accuracy: 0.9618\n",
            "Epoch 24/30\n",
            "8/8 [==============================] - 1s 73ms/step - loss: 0.5696 - accuracy: 0.9979 - val_loss: 0.6844 - val_accuracy: 0.9596\n",
            "Epoch 25/30\n",
            "8/8 [==============================] - 1s 75ms/step - loss: 0.5587 - accuracy: 0.9979 - val_loss: 0.6748 - val_accuracy: 0.9596\n",
            "Epoch 26/30\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 0.5479 - accuracy: 0.9972 - val_loss: 0.6640 - val_accuracy: 0.9618\n",
            "Epoch 27/30\n",
            "8/8 [==============================] - 0s 61ms/step - loss: 0.5379 - accuracy: 0.9979 - val_loss: 0.6538 - val_accuracy: 0.9618\n",
            "Epoch 28/30\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 0.5280 - accuracy: 0.9979 - val_loss: 0.6434 - val_accuracy: 0.9618\n",
            "Epoch 29/30\n",
            "8/8 [==============================] - 1s 74ms/step - loss: 0.5186 - accuracy: 0.9986 - val_loss: 0.6343 - val_accuracy: 0.9596\n",
            "Epoch 30/30\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 0.5098 - accuracy: 0.9972 - val_loss: 0.6251 - val_accuracy: 0.9596\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wnioski: Najlepsze wynik otrzymano w trakcie eksperymentów z szerokością sieci."
      ],
      "metadata": {
        "id": "aewnK0tFa0GC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regresja logistyczna\n",
        "Dodatkowo porównuję z wynikiem prostszego klasyfikatora."
      ],
      "metadata": {
        "id": "EzWxPPDwb1jl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "lgr = LogisticRegression()\n",
        "\n",
        "# Przekształacam one-hot encoded labelki na etykiety liczb całkowitych\n",
        "y_train_labels = np.argmax(y_train_ready, axis=1)\n",
        "y_test_labels = np.argmax(y_test_ready, axis=1)\n",
        "\n",
        "lgr.fit(x_train_ready, y_train_labels)\n",
        "predicted_labels = lgr.predict(x_test_ready)\n",
        "\n",
        "accuracy_of_model = accuracy_score(y_test_labels, predicted_labels)\n",
        "print(\"Accuracy\", accuracy_of_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S562rotMbKev",
        "outputId": "54ff1125-5a50-4ea2-9950-ba9827e5e953"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy is 0.9662921348314607\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PODSUMOWANIE"
      ],
      "metadata": {
        "id": "PtS7dx-BefCd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podczas wykonywanych eksperymentów udało się poprawić Accuracy (dokładność) modelu na danych testowych z 0.9730 (ok 97%) w modelu referencyjnym do 0.9775 (ok 98%). Dodatkowo osiągnał on także lepszą dokładność niż model regresji logistycznej, który miał Accuracy 0.9662 (ok 97%) Poniżej zamieściłam porównanie najlepszego modelu wraz z modelem referencyjnym i dodałam raporty dot. F1-score, precision, recall i oczywiście Accuracy."
      ],
      "metadata": {
        "id": "SniZkZ7hehTL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model referencyjny na zbiorze testowym"
      ],
      "metadata": {
        "id": "YEWEIr74zYfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train_ready, y_train_ready,\n",
        "                    epochs=30, batch_size=200,\n",
        "                    validation_data=(x_test_ready, y_test_ready))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4379d9dd-05d4-470b-b353-3fdd69aec017",
        "id": "pIi_OM1lzWWJ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "8/8 [==============================] - 2s 70ms/step - loss: 1.6027 - accuracy: 0.4185 - val_loss: 1.5856 - val_accuracy: 0.5596\n",
            "Epoch 2/30\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 1.5650 - accuracy: 0.6685 - val_loss: 1.5459 - val_accuracy: 0.6427\n",
            "Epoch 3/30\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 1.5126 - accuracy: 0.7500 - val_loss: 1.4975 - val_accuracy: 0.7124\n",
            "Epoch 4/30\n",
            "8/8 [==============================] - 0s 47ms/step - loss: 1.4479 - accuracy: 0.8378 - val_loss: 1.4405 - val_accuracy: 0.7551\n",
            "Epoch 5/30\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 1.3730 - accuracy: 0.8848 - val_loss: 1.3757 - val_accuracy: 0.7798\n",
            "Epoch 6/30\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 1.2880 - accuracy: 0.9263 - val_loss: 1.3031 - val_accuracy: 0.8202\n",
            "Epoch 7/30\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 1.1935 - accuracy: 0.9473 - val_loss: 1.2233 - val_accuracy: 0.8494\n",
            "Epoch 8/30\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 1.0904 - accuracy: 0.9677 - val_loss: 1.1369 - val_accuracy: 0.8652\n",
            "Epoch 9/30\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.9813 - accuracy: 0.9747 - val_loss: 1.0464 - val_accuracy: 0.8697\n",
            "Epoch 10/30\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.8694 - accuracy: 0.9789 - val_loss: 0.9525 - val_accuracy: 0.8854\n",
            "Epoch 11/30\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.7561 - accuracy: 0.9860 - val_loss: 0.8574 - val_accuracy: 0.9034\n",
            "Epoch 12/30\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.6478 - accuracy: 0.9888 - val_loss: 0.7669 - val_accuracy: 0.9191\n",
            "Epoch 13/30\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.5493 - accuracy: 0.9923 - val_loss: 0.6822 - val_accuracy: 0.9236\n",
            "Epoch 14/30\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.4618 - accuracy: 0.9951 - val_loss: 0.6071 - val_accuracy: 0.9258\n",
            "Epoch 15/30\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 0.3867 - accuracy: 0.9972 - val_loss: 0.5406 - val_accuracy: 0.9326\n",
            "Epoch 16/30\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.3224 - accuracy: 0.9986 - val_loss: 0.4823 - val_accuracy: 0.9438\n",
            "Epoch 17/30\n",
            "8/8 [==============================] - 0s 63ms/step - loss: 0.2679 - accuracy: 0.9986 - val_loss: 0.4313 - val_accuracy: 0.9461\n",
            "Epoch 18/30\n",
            "8/8 [==============================] - 0s 62ms/step - loss: 0.2223 - accuracy: 0.9986 - val_loss: 0.3875 - val_accuracy: 0.9483\n",
            "Epoch 19/30\n",
            "8/8 [==============================] - 0s 63ms/step - loss: 0.1847 - accuracy: 0.9986 - val_loss: 0.3503 - val_accuracy: 0.9528\n",
            "Epoch 20/30\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 0.1536 - accuracy: 0.9993 - val_loss: 0.3185 - val_accuracy: 0.9640\n",
            "Epoch 21/30\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.1284 - accuracy: 1.0000 - val_loss: 0.2916 - val_accuracy: 0.9685\n",
            "Epoch 22/30\n",
            "8/8 [==============================] - 0s 48ms/step - loss: 0.1078 - accuracy: 1.0000 - val_loss: 0.2685 - val_accuracy: 0.9708\n",
            "Epoch 23/30\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 0.0913 - accuracy: 1.0000 - val_loss: 0.2485 - val_accuracy: 0.9730\n",
            "Epoch 24/30\n",
            "8/8 [==============================] - 0s 49ms/step - loss: 0.0777 - accuracy: 1.0000 - val_loss: 0.2321 - val_accuracy: 0.9730\n",
            "Epoch 25/30\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.0666 - accuracy: 1.0000 - val_loss: 0.2182 - val_accuracy: 0.9730\n",
            "Epoch 26/30\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.0578 - accuracy: 1.0000 - val_loss: 0.2061 - val_accuracy: 0.9730\n",
            "Epoch 27/30\n",
            "8/8 [==============================] - 0s 48ms/step - loss: 0.0506 - accuracy: 1.0000 - val_loss: 0.1960 - val_accuracy: 0.9730\n",
            "Epoch 28/30\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.0447 - accuracy: 1.0000 - val_loss: 0.1872 - val_accuracy: 0.9708\n",
            "Epoch 29/30\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.0396 - accuracy: 1.0000 - val_loss: 0.1797 - val_accuracy: 0.9708\n",
            "Epoch 30/30\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0354 - accuracy: 1.0000 - val_loss: 0.1730 - val_accuracy: 0.9730\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Generuję predykcję na testowym i przekształcam przewidywania\n",
        "#z zakodowanego formatu one-hot na etykiety\n",
        "y_predition = model.predict(x_test_ready)\n",
        "y_pred_labels = np.argmax(y_predition, axis=1)\n",
        "\n",
        "# Generuję classification raport\n",
        "report = classification_report(y_test_labels, y_pred_labels, target_names=label_encoder.classes_)\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6915ae44-f3fe-4766-db1a-325b63b3b134",
        "id": "eAvvFQLezzAj"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14/14 [==============================] - 0s 2ms/step\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     business       0.96      0.95      0.96       101\n",
            "entertainment       1.00      0.95      0.97        81\n",
            "     politics       0.94      0.98      0.96        83\n",
            "        sport       0.99      1.00      0.99        98\n",
            "         tech       0.98      0.99      0.98        82\n",
            "\n",
            "     accuracy                           0.97       445\n",
            "    macro avg       0.97      0.97      0.97       445\n",
            " weighted avg       0.97      0.97      0.97       445\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NAJLEPSZY MODEL Z REGULARYZACJA L2 (0.002) ORAZ 64 NEURONAMI W 1 I 32 w 2 WARSTWIE"
      ],
      "metadata": {
        "id": "PEqLrr2Vc7qi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(64, kernel_regularizer=regularizers.l2(0.002), activation=\"relu\"),\n",
        "    Dense(32, kernel_regularizer=regularizers.l2(0.002), activation=\"relu\"),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train_ready, y_train_ready,\n",
        "                    epochs=30, batch_size=200,\n",
        "                    validation_data=(x_test_ready, y_test_ready))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e81a9d00-26e4-4def-d34f-ac89ac3b86ad",
        "id": "RAqlVgQ2yX5r"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "8/8 [==============================] - 2s 126ms/step - loss: 1.8345 - accuracy: 0.4684 - val_loss: 1.6797 - val_accuracy: 0.6989\n",
            "Epoch 2/30\n",
            "8/8 [==============================] - 1s 115ms/step - loss: 1.6030 - accuracy: 0.7963 - val_loss: 1.5321 - val_accuracy: 0.7730\n",
            "Epoch 3/30\n",
            "8/8 [==============================] - 1s 98ms/step - loss: 1.4520 - accuracy: 0.8933 - val_loss: 1.4201 - val_accuracy: 0.8157\n",
            "Epoch 4/30\n",
            "8/8 [==============================] - 1s 115ms/step - loss: 1.3141 - accuracy: 0.9403 - val_loss: 1.3024 - val_accuracy: 0.8539\n",
            "Epoch 5/30\n",
            "8/8 [==============================] - 1s 117ms/step - loss: 1.1717 - accuracy: 0.9600 - val_loss: 1.1836 - val_accuracy: 0.8921\n",
            "Epoch 6/30\n",
            "8/8 [==============================] - 1s 91ms/step - loss: 1.0340 - accuracy: 0.9684 - val_loss: 1.0684 - val_accuracy: 0.9258\n",
            "Epoch 7/30\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.9075 - accuracy: 0.9895 - val_loss: 0.9617 - val_accuracy: 0.9461\n",
            "Epoch 8/30\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 0.7965 - accuracy: 0.9951 - val_loss: 0.8665 - val_accuracy: 0.9528\n",
            "Epoch 9/30\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 0.7032 - accuracy: 0.9972 - val_loss: 0.7892 - val_accuracy: 0.9573\n",
            "Epoch 10/30\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.6314 - accuracy: 0.9986 - val_loss: 0.7304 - val_accuracy: 0.9663\n",
            "Epoch 11/30\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 0.5776 - accuracy: 0.9986 - val_loss: 0.6829 - val_accuracy: 0.9730\n",
            "Epoch 12/30\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 0.5356 - accuracy: 0.9993 - val_loss: 0.6479 - val_accuracy: 0.9685\n",
            "Epoch 13/30\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 0.5032 - accuracy: 0.9993 - val_loss: 0.6172 - val_accuracy: 0.9730\n",
            "Epoch 14/30\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.4765 - accuracy: 0.9993 - val_loss: 0.5919 - val_accuracy: 0.9730\n",
            "Epoch 15/30\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 0.4542 - accuracy: 0.9993 - val_loss: 0.5719 - val_accuracy: 0.9730\n",
            "Epoch 16/30\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 0.4357 - accuracy: 0.9993 - val_loss: 0.5539 - val_accuracy: 0.9730\n",
            "Epoch 17/30\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 0.4197 - accuracy: 1.0000 - val_loss: 0.5386 - val_accuracy: 0.9730\n",
            "Epoch 18/30\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 0.4057 - accuracy: 1.0000 - val_loss: 0.5262 - val_accuracy: 0.9753\n",
            "Epoch 19/30\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.3934 - accuracy: 1.0000 - val_loss: 0.5150 - val_accuracy: 0.9730\n",
            "Epoch 20/30\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 0.3828 - accuracy: 1.0000 - val_loss: 0.5030 - val_accuracy: 0.9730\n",
            "Epoch 21/30\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 0.3725 - accuracy: 1.0000 - val_loss: 0.4929 - val_accuracy: 0.9753\n",
            "Epoch 22/30\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 0.3634 - accuracy: 1.0000 - val_loss: 0.4822 - val_accuracy: 0.9775\n",
            "Epoch 23/30\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 0.3548 - accuracy: 1.0000 - val_loss: 0.4759 - val_accuracy: 0.9753\n",
            "Epoch 24/30\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.3484 - accuracy: 1.0000 - val_loss: 0.4687 - val_accuracy: 0.9730\n",
            "Epoch 25/30\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 0.3414 - accuracy: 1.0000 - val_loss: 0.4596 - val_accuracy: 0.9775\n",
            "Epoch 26/30\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 0.3348 - accuracy: 1.0000 - val_loss: 0.4536 - val_accuracy: 0.9753\n",
            "Epoch 27/30\n",
            "8/8 [==============================] - 1s 90ms/step - loss: 0.3293 - accuracy: 1.0000 - val_loss: 0.4468 - val_accuracy: 0.9730\n",
            "Epoch 28/30\n",
            "8/8 [==============================] - 1s 104ms/step - loss: 0.3238 - accuracy: 1.0000 - val_loss: 0.4432 - val_accuracy: 0.9798\n",
            "Epoch 29/30\n",
            "8/8 [==============================] - 1s 105ms/step - loss: 0.3184 - accuracy: 1.0000 - val_loss: 0.4376 - val_accuracy: 0.9730\n",
            "Epoch 30/30\n",
            "8/8 [==============================] - 1s 91ms/step - loss: 0.3132 - accuracy: 1.0000 - val_loss: 0.4320 - val_accuracy: 0.9775\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Generuję predykcję na testowym i przekształcam przewidywania\n",
        "#z zakodowanego formatu one-hot na etykiety\n",
        "y_predition = model.predict(x_test_ready)\n",
        "y_pred_labels = np.argmax(y_predition, axis=1)\n",
        "# Generuję classification raport\n",
        "report = classification_report(y_test_labels, y_pred_labels, target_names=label_encoder.classes_)\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXwOKipdeQQC",
        "outputId": "fd89a3d6-34fa-42c1-ce42-31bf28762bfc"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14/14 [==============================] - 0s 12ms/step\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     business       0.97      0.95      0.96       101\n",
            "entertainment       1.00      0.98      0.99        81\n",
            "     politics       0.96      0.98      0.97        83\n",
            "        sport       0.98      1.00      0.99        98\n",
            "         tech       0.96      0.98      0.97        82\n",
            "\n",
            "     accuracy                           0.98       445\n",
            "    macro avg       0.98      0.98      0.98       445\n",
            " weighted avg       0.98      0.98      0.98       445\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}